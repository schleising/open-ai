{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Simple Openai","text":"<p>This is a simple wrapper for the OpenAI API, which allows you to easily use the API in your projects.</p> <p>It provides both synchronous and asynchronous versions of the wrapper.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install using pip:</p> <pre><code>pip install simple-openai\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#calling-the-api","title":"Calling the API","text":"<p>For the synchronous version, you can use the following code:</p> <p>Synchronous Version</p> <pre><code>from simple_openai import SimpleOpenai\n\ndef main():\n    # Initialise a storage location\n    storage_location = Path(\"/path/to/storage\")\n\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = SimpleOpenai(api_key, system_message, storage_location)\n\n    # Create tasks for the chat response and the image response\n    result = client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\n    result = client.get_image_url(\"A cat\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    main()\n</code></pre> <p>For the asynchronous version, you can use the following code:</p> <p>Asynchronous Version</p> <pre><code>from simple_openai import AsyncSimpleOpenai\nimport asyncio\n\nasync def main():\n    # Initialise a storage location\n    storage_location = Path(\"/path/to/storage\")\n\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = AsyncSimpleOpenai(api_key, system_message, storage_location)\n\n    # Create tasks for the chat response and the image response\n    tasks = [\n        client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\"),\n        client.get_image_url(\"A cat\"),\n    ]\n\n    # Wait for the tasks to complete\n    for task in asyncio.as_completed(tasks):\n        # Get the result\n        result = await task\n\n        # Print the result\n        if result.success:\n            # Print the message\n            print(f'Success: {result.message}')\n        else:\n            # Print the error\n            print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    asyncio.run(main())\n</code></pre>"},{"location":"#output","title":"Output","text":"<p>The output of the functions is a SimpleOpenaiResponse object, which contains the following properties:</p> <ul> <li><code>success</code> - A boolean indicating whether the request was successful or not.</li> <li><code>message</code> - The message returned by the API.</li> </ul>"},{"location":"#documentation","title":"Documentation","text":"<p>The documentation for the package can be found in the reference section.</p>"},{"location":"simple_openai/async_simple_openai/","title":"AsyncSimpleOpenai","text":"<p>Async Simple OpenAI API wrapper</p> <p>The is the async version of the Simple OpenAI API wrapper which uses the <code>aiohttp</code> library.</p> <p>It is intended for use with asyncio applications.  If you are not using asyncio, you should use the Simple OpenAI API wrapper instead.</p>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai","title":"<code>AsyncSimpleOpenai</code>","text":"<p>Async Simple OpenAI API wrapper</p> <p>This class implements the Async Simple OpenAI API wrapper.</p> <p>To use this class, you need to have an OpenAI API key. You can get one from Openai.</p> <p>An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Your OpenAI API key</p> required <code>system_message</code> <code>str</code> <p>The system message to add to the start of the chat</p> required <code>storage_path</code> <code>Path</code> <p>The path to the storage directory. Defaults to None.</p> <code>None</code> <p>Example</p> <pre><code>from simple_openai import AsyncSimpleOpenai\nimport asyncio\n\nasync def main():\n    # Get the storage path\n    storage_path = Path(\"/path/to/storage\")\n\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = AsyncSimpleOpenai(api_key, system_message, storage_path)\n\n    # Create tasks for the chat response and the image response\n    tasks = [\n        client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\"),\n        client.get_image_url(\"A cat\"),\n    ]\n\n    # Wait for the tasks to complete\n    for task in asyncio.as_completed(tasks):\n        # Get the result\n        result = await task\n\n        # Print the result\n        if result.success:\n            # Print the message\n            print(f'Success: {result.message}')\n        else:\n            # Print the error\n            print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    asyncio.run(main())\n</code></pre> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>class AsyncSimpleOpenai:\n\"\"\"Async Simple OpenAI API wrapper\n\n    This class implements the Async Simple OpenAI API wrapper.\n\n    To use this class, you need to have an OpenAI API key. You can get one from [Openai](https://platform.openai.com).\n\n    An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.\n\n    Args:\n        api_key (str): Your OpenAI API key\n        system_message (str): The system message to add to the start of the chat\n        storage_path (Path, optional): The path to the storage directory. Defaults to None.\n\n    !!!Example\n        ```python\n        from simple_openai import AsyncSimpleOpenai\n        import asyncio\n\n        async def main():\n            # Get the storage path\n            storage_path = Path(\"/path/to/storage\")\n\n            # Create a system message\n            system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n            # Create the client\n            client = AsyncSimpleOpenai(api_key, system_message, storage_path)\n\n            # Create tasks for the chat response and the image response\n            tasks = [\n                client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\"),\n                client.get_image_url(\"A cat\"),\n            ]\n\n            # Wait for the tasks to complete\n            for task in asyncio.as_completed(tasks):\n                # Get the result\n                result = await task\n\n                # Print the result\n                if result.success:\n                    # Print the message\n                    print(f'Success: {result.message}')\n                else:\n                    # Print the error\n                    print(f'Error: {result.message}')\n\n        if __name__ == \"__main__\":\n            # Run the main function\n            asyncio.run(main())\n        ```\n    \"\"\"\n    def __init__(self, api_key: str, system_message: str, storage_path: Path | None = None) -&gt; None:\n        self._headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {api_key}'\n        }\n\n        # Create the chat manager\n        self._chat = chat_manager.ChatManager(system_message, storage_path=storage_path)\n\n    async def get_chat_response(self, prompt: str, name: str, chat_id: str = constants.DEFAULT_CHAT_ID) -&gt; SimpleOpenaiResponse:\n\"\"\"Get a chat response from OpenAI\n\n        An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n        Args:\n            prompt (str): The prompt to use for the chat response\n            name (str): The name of the user\n            chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n\n        Returns:\n            SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n\n        \"\"\"\n        # Add the message to the chat\n        messages = self._chat.add_message(open_ai_models.ChatMessage(role='user', content=prompt, name=name), chat_id=chat_id).messages        \n\n        # Create the request body\n        request_body = open_ai_models.ChatRequest(messages=messages)\n\n        # Open a session\n        async with aiohttp.ClientSession(headers=self._headers, base_url=constants.BASE_URL) as session:\n            # Send the request\n            async with session.post(constants.CHAT_URL, json=request_body.dict()) as response:\n                # Check the status code\n                if response.status == 200:\n                    # Parse the response body\n                    response_body = open_ai_models.ChatResponse.parse_raw(await response.text())\n\n                    # Create the response\n                    response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n\n                    # Add the response to the chat\n                    self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=response.message, name='Botto'))\n                else:\n                    # Parse the error response body\n                    response_body = open_ai_models.ErrorResponse.parse_raw(await response.text())\n\n                    # Create the response\n                    response = SimpleOpenaiResponse(False, response_body.error.message)\n\n                # Return the response\n                return response\n\n    async def get_image_url(self, prompt: str) -&gt; SimpleOpenaiResponse:\n\"\"\"Get an image response from OpenAI\n\n        Args:\n            prompt (str): The prompt to use\n\n        Returns:\n            SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n        \"\"\"\n\n        # Create the request body\n        request_body = open_ai_models.ImageRequest(prompt=prompt)\n\n        # Open a session\n        async with aiohttp.ClientSession(headers=self._headers, base_url=constants.BASE_URL) as session:\n            # Send the request\n            async with session.post(constants.IMAGE_URL, json=request_body.dict()) as response:\n                # Check the status code\n                if response.status == 200:\n                    # Parse the response body\n                    response_body = open_ai_models.ImageResponse.parse_raw(await response.text())\n\n                    # Create the response\n                    response = SimpleOpenaiResponse(True, response_body.data[0].url)\n                else:\n                    # Parse the error response body\n                    response_body = open_ai_models.ErrorResponse.parse_raw(await response.text())\n\n                    # Create the response\n                    response = SimpleOpenaiResponse(False, response_body.error.message)\n\n                # Return the response\n                return response\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.get_chat_response","title":"<code>get_chat_response(prompt, name, chat_id=constants.DEFAULT_CHAT_ID)</code>  <code>async</code>","text":"<p>Get a chat response from OpenAI</p> <p>An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use for the chat response</p> required <code>name</code> <code>str</code> <p>The name of the user</p> required <code>chat_id</code> <code>str</code> <p>The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.</p> <code>constants.DEFAULT_CHAT_ID</code> <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The chat response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>async def get_chat_response(self, prompt: str, name: str, chat_id: str = constants.DEFAULT_CHAT_ID) -&gt; SimpleOpenaiResponse:\n\"\"\"Get a chat response from OpenAI\n\n    An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n    Args:\n        prompt (str): The prompt to use for the chat response\n        name (str): The name of the user\n        chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n\n    Returns:\n        SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n\n    \"\"\"\n    # Add the message to the chat\n    messages = self._chat.add_message(open_ai_models.ChatMessage(role='user', content=prompt, name=name), chat_id=chat_id).messages        \n\n    # Create the request body\n    request_body = open_ai_models.ChatRequest(messages=messages)\n\n    # Open a session\n    async with aiohttp.ClientSession(headers=self._headers, base_url=constants.BASE_URL) as session:\n        # Send the request\n        async with session.post(constants.CHAT_URL, json=request_body.dict()) as response:\n            # Check the status code\n            if response.status == 200:\n                # Parse the response body\n                response_body = open_ai_models.ChatResponse.parse_raw(await response.text())\n\n                # Create the response\n                response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n\n                # Add the response to the chat\n                self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=response.message, name='Botto'))\n            else:\n                # Parse the error response body\n                response_body = open_ai_models.ErrorResponse.parse_raw(await response.text())\n\n                # Create the response\n                response = SimpleOpenaiResponse(False, response_body.error.message)\n\n            # Return the response\n            return response\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.get_image_url","title":"<code>get_image_url(prompt)</code>  <code>async</code>","text":"<p>Get an image response from OpenAI</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use</p> required <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The image response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>async def get_image_url(self, prompt: str) -&gt; SimpleOpenaiResponse:\n\"\"\"Get an image response from OpenAI\n\n    Args:\n        prompt (str): The prompt to use\n\n    Returns:\n        SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n    \"\"\"\n\n    # Create the request body\n    request_body = open_ai_models.ImageRequest(prompt=prompt)\n\n    # Open a session\n    async with aiohttp.ClientSession(headers=self._headers, base_url=constants.BASE_URL) as session:\n        # Send the request\n        async with session.post(constants.IMAGE_URL, json=request_body.dict()) as response:\n            # Check the status code\n            if response.status == 200:\n                # Parse the response body\n                response_body = open_ai_models.ImageResponse.parse_raw(await response.text())\n\n                # Create the response\n                response = SimpleOpenaiResponse(True, response_body.data[0].url)\n            else:\n                # Parse the error response body\n                response_body = open_ai_models.ErrorResponse.parse_raw(await response.text())\n\n                # Create the response\n                response = SimpleOpenaiResponse(False, response_body.error.message)\n\n            # Return the response\n            return response\n</code></pre>"},{"location":"simple_openai/chat_manager/","title":"ChatManager","text":"<p>Chat manager for the simple openai app</p> <p>This module contains the chat manager for the simple openai app.</p> <p>The chat manager is used to manage the chat messages and create the chat, it limits the number of messages in the chat to 21 by default and adds the system message to the start of the list.</p>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager","title":"<code>ChatManager</code>","text":"<p>The chat manager</p> <p>This class is used to manage the chat messages and create the chat, it limits the number of messages in the chat to 21 by default and adds the system message to the start of the list.</p> <p>It can optionally handle messages from multiple chats separately and store them in a file.</p> <p>On initialisation, the chat manager will try to load the chat history from the file.  If the file does not exist, it will create a new chat history.</p> <p>Parameters:</p> Name Type Description Default <code>system_message</code> <code>str</code> <p>The system message to add to the start of the chat</p> required <code>max_messages</code> <code>int</code> <p>The maximum number of messages in the chat. Defaults to 21.</p> <code>MAX_CHAT_HISTORY</code> <code>storage_path</code> <code>Path</code> <p>The path to the storage directory. Defaults to None.</p> <code>None</code> Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>class ChatManager:\n\"\"\"The chat manager\n\n    This class is used to manage the chat messages and create the chat, it limits the number of messages in the chat to 21 by default and adds the system message to the start of the list.\n\n    It can optionally handle messages from multiple chats separately and store them in a file.\n\n    On initialisation, the chat manager will try to load the chat history from the file.  If the file does not exist, it will create a new chat history.\n\n    Args:\n        system_message (str): The system message to add to the start of the chat\n        max_messages (int, optional): The maximum number of messages in the chat. Defaults to 21.\n        storage_path (Path, optional): The path to the storage directory. Defaults to None.\n    \"\"\"\n    def __init__(self, system_message: str, max_messages: int = MAX_CHAT_HISTORY, storage_path: Path | None = None) -&gt; None:\n        self._system_message = system_message\n        self._max_messages = max_messages\n        self._storage_path = storage_path\n\n        # If a storage path is provided, create the storage directory\n        if self._storage_path is not None:\n            self._storage_path.mkdir(parents=True, exist_ok=True)\n\n            # Try to load the chat history\n            try:\n                # Load the chat history\n                with open(self._storage_path / CHAT_HISTORY_FILE, 'rb') as f:\n                    # Load the chat history\n                    self._messages: dict[str, deque[open_ai_models.ChatMessage]] = pickle.load(f)\n            except FileNotFoundError:\n                # initialise a deque of messages not including the system message\n                self._messages: dict[str, deque[open_ai_models.ChatMessage]] = {}\n        else:\n            # initialise a deque of messages not including the system message\n            self._messages: dict[str, deque[open_ai_models.ChatMessage]] = {}\n\n    def add_message(self, message: open_ai_models.ChatMessage, chat_id: str = DEFAULT_CHAT_ID) -&gt; open_ai_models.Chat:\n\"\"\"Add a message to the chat\n\n        Args:\n            message (open_ai_models.ChatMessage): The message to add to the chat\n            chat_id (str, optional): The ID of the chat to add the message to. Defaults to DEFAULT_CHAT_ID.\n\n        Returns:\n            open_ai_models.Chat: The chat\n        \"\"\"\n        # If the chat ID is not in the messages, create a new deque\n        if chat_id not in self._messages:\n            self._messages[chat_id] = deque(maxlen=self._max_messages)\n\n        # Add the message to the deque\n        self._messages[chat_id].append(message)\n\n        # If a storage path is provided, save the chat history\n        if self._storage_path is not None:\n            # Save the chat history\n            with open(self._storage_path / CHAT_HISTORY_FILE, 'wb') as f:\n                pickle.dump(self._messages, f)\n\n        # Create the chat adding the system message to the start\n        chat = open_ai_models.Chat(messages=[\n            open_ai_models.ChatMessage(role='system', content=self._system_message, name='System')\n        ] + list(self._messages[chat_id]))\n\n        # Return the chat\n        return chat\n</code></pre>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager.add_message","title":"<code>add_message(message, chat_id=DEFAULT_CHAT_ID)</code>","text":"<p>Add a message to the chat</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>open_ai_models.ChatMessage</code> <p>The message to add to the chat</p> required <code>chat_id</code> <code>str</code> <p>The ID of the chat to add the message to. Defaults to DEFAULT_CHAT_ID.</p> <code>DEFAULT_CHAT_ID</code> <p>Returns:</p> Type Description <code>open_ai_models.Chat</code> <p>open_ai_models.Chat: The chat</p> Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>def add_message(self, message: open_ai_models.ChatMessage, chat_id: str = DEFAULT_CHAT_ID) -&gt; open_ai_models.Chat:\n\"\"\"Add a message to the chat\n\n    Args:\n        message (open_ai_models.ChatMessage): The message to add to the chat\n        chat_id (str, optional): The ID of the chat to add the message to. Defaults to DEFAULT_CHAT_ID.\n\n    Returns:\n        open_ai_models.Chat: The chat\n    \"\"\"\n    # If the chat ID is not in the messages, create a new deque\n    if chat_id not in self._messages:\n        self._messages[chat_id] = deque(maxlen=self._max_messages)\n\n    # Add the message to the deque\n    self._messages[chat_id].append(message)\n\n    # If a storage path is provided, save the chat history\n    if self._storage_path is not None:\n        # Save the chat history\n        with open(self._storage_path / CHAT_HISTORY_FILE, 'wb') as f:\n            pickle.dump(self._messages, f)\n\n    # Create the chat adding the system message to the start\n    chat = open_ai_models.Chat(messages=[\n        open_ai_models.ChatMessage(role='system', content=self._system_message, name='System')\n    ] + list(self._messages[chat_id]))\n\n    # Return the chat\n    return chat\n</code></pre>"},{"location":"simple_openai/responses/","title":"SimpleOpenaiResponse","text":""},{"location":"simple_openai/responses/#src.simple_openai.responses.SimpleOpenaiResponse","title":"<code>SimpleOpenaiResponse</code>  <code>dataclass</code>","text":"<p>Simple OpenAI API response</p> <p>This class represents a response from the Simple OpenAI API.</p> <p>The value of <code>success</code> should be checked before using the value of <code>message</code>.</p> <p>If <code>success</code> is True,</p> <ul> <li>For a chat response, <code>message</code> will contain the chat response.</li> <li>For an image response, <code>message</code> will contain the image URL.</li> </ul> <p>If <code>success</code> is False, <code>message</code> will contain the error message.</p> <p>Parameters:</p> Name Type Description Default <code>success</code> <code>bool</code> <p>True if the request was successful, False otherwise</p> required <code>message</code> <code>str</code> <p>The message of the response</p> required Source code in <code>src/simple_openai/responses.py</code> <pre><code>@dataclass\nclass SimpleOpenaiResponse:\n\"\"\"Simple OpenAI API response\n\n    This class represents a response from the Simple OpenAI API.\n\n    The value of `success` should be checked before using the value of `message`.\n\n    If `success` is True,\n\n    - For a chat response, `message` will contain the chat response.\n    - For an image response, `message` will contain the image URL.\n\n    If `success` is False, `message` will contain the error message.\n\n    Args:\n        success (bool): True if the request was successful, False otherwise\n        message (str): The message of the response\n    \"\"\"\n    success: bool\n    message: str\n</code></pre>"},{"location":"simple_openai/simple_openai/","title":"SimpleOpenai","text":"<p>Simple OpenAI API wrapper</p> <p>The is the synchronous version of the Simple OpenAI API wrapper which uses the <code>requests</code> library.</p> <p>If you wish to use the async version, you should use the AsyncSimple OpenAI API wrapper instead.</p>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai","title":"<code>SimpleOpenai</code>","text":"<p>Simple OpenAI API wrapper</p> <p>This class implements the Simple OpenAI API wrapper.</p> <p>To use this class, you need to have an OpenAI API key. You can get one from Openai.</p> <p>An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Your OpenAI API key</p> required <code>system_message</code> <code>str</code> <p>The system message to add to the start of the chat</p> required <code>storage_path</code> <code>Path</code> <p>The path to the storage directory. Defaults to None.</p> <code>None</code> <p>Example</p> <pre><code>from simple_openai import SimpleOpenai\n\ndef main():\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = SimpleOpenai(api_key, system_message)\n\n    # Create tasks for the chat response and the image response\n    result = client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\n    result = client.get_image_url(\"A cat\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    main()\n</code></pre> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>class SimpleOpenai:\n\"\"\"Simple OpenAI API wrapper\n\n    This class implements the Simple OpenAI API wrapper.\n\n    To use this class, you need to have an OpenAI API key. You can get one from [Openai](https://platform.openai.com).\n\n    An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.\n\n    Args:\n        api_key (str): Your OpenAI API key\n        system_message (str): The system message to add to the start of the chat\n        storage_path (Path, optional): The path to the storage directory. Defaults to None.\n\n    !!!Example\n        ```python\n        from simple_openai import SimpleOpenai\n\n        def main():\n            # Create a system message\n            system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n            # Create the client\n            client = SimpleOpenai(api_key, system_message)\n\n            # Create tasks for the chat response and the image response\n            result = client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\")\n\n            # Print the result\n            if result.success:\n                # Print the message\n                print(f'Success: {result.message}')\n            else:\n                # Print the error\n                print(f'Error: {result.message}')\n\n            result = client.get_image_url(\"A cat\")\n\n            # Print the result\n            if result.success:\n                # Print the message\n                print(f'Success: {result.message}')\n            else:\n                # Print the error\n                print(f'Error: {result.message}')\n\n        if __name__ == \"__main__\":\n            # Run the main function\n            main()\n        ```\n    \"\"\"\n    def __init__(self, api_key: str, system_message: str, storage_path: Path | None = None) -&gt; None:\n        self._headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {api_key}'\n        }\n\n        # Create the chat manager\n        self._chat = chat_manager.ChatManager(system_message, storage_path=storage_path)\n\n    def get_chat_response(self, prompt: str, name: str, chat_id: str = constants.DEFAULT_CHAT_ID) -&gt; SimpleOpenaiResponse:\n\"\"\"Get a chat response from OpenAI\n\n        An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n        Args:\n            prompt (str): The prompt to use for the chat response\n            name (str): The name of the person talking to the bot\n            chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n\n        Returns:\n            SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n        \"\"\"\n\n        # Create the request body\n        messages = self._chat.add_message(open_ai_models.ChatMessage(role='user', content=prompt, name=name), chat_id=chat_id).messages        \n\n        # Create the request body\n        request_body = open_ai_models.ChatRequest(messages=messages)\n\n        # Send the request\n        response = requests.post(constants.FULL_CHAT_URL, json=request_body.dict(), headers=self._headers)\n\n        # Check the status code\n        if response.status_code == requests.codes.OK:\n            # Parse the response body\n            response_body = open_ai_models.ChatResponse.parse_raw(response.text)\n\n            # Create the response\n            response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n\n            # Add the response to the chat\n            self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=response.message, name='Botto'))\n        else:\n            # Parse the error response body\n            response_body = open_ai_models.ErrorResponse.parse_raw(response.text)\n\n            # Create the response\n            response = SimpleOpenaiResponse(False, response_body.error.message)\n\n        # Return the response\n        return response\n\n    def get_image_url(self, prompt: str) -&gt; SimpleOpenaiResponse:\n\"\"\"Get an image response from OpenAI\n\n        Args:\n            prompt (str): The prompt to use\n\n        Returns:\n            SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n        \"\"\"\n\n        # Create the request body\n        request_body = open_ai_models.ImageRequest(prompt=prompt)\n\n        # Send the request\n        response = requests.post(constants.FULL_IMAGE_URL, json=request_body.dict(), headers=self._headers)\n\n        # Check the status code\n        if response.status_code == requests.codes.OK:\n            # Parse the response body\n            response_body = open_ai_models.ImageResponse.parse_raw(response.text)\n\n            # Create the response\n            response = SimpleOpenaiResponse(True, response_body.data[0].url)\n        else:\n            # Parse the error response body\n            response_body = open_ai_models.ErrorResponse.parse_raw(response.text)\n\n            # Create the response\n            response = SimpleOpenaiResponse(False, response_body.error.message)\n\n        # Return the response\n        return response\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.get_chat_response","title":"<code>get_chat_response(prompt, name, chat_id=constants.DEFAULT_CHAT_ID)</code>","text":"<p>Get a chat response from OpenAI</p> <p>An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use for the chat response</p> required <code>name</code> <code>str</code> <p>The name of the person talking to the bot</p> required <code>chat_id</code> <code>str</code> <p>The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.</p> <code>constants.DEFAULT_CHAT_ID</code> <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The chat response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def get_chat_response(self, prompt: str, name: str, chat_id: str = constants.DEFAULT_CHAT_ID) -&gt; SimpleOpenaiResponse:\n\"\"\"Get a chat response from OpenAI\n\n    An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n    Args:\n        prompt (str): The prompt to use for the chat response\n        name (str): The name of the person talking to the bot\n        chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n\n    Returns:\n        SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n    \"\"\"\n\n    # Create the request body\n    messages = self._chat.add_message(open_ai_models.ChatMessage(role='user', content=prompt, name=name), chat_id=chat_id).messages        \n\n    # Create the request body\n    request_body = open_ai_models.ChatRequest(messages=messages)\n\n    # Send the request\n    response = requests.post(constants.FULL_CHAT_URL, json=request_body.dict(), headers=self._headers)\n\n    # Check the status code\n    if response.status_code == requests.codes.OK:\n        # Parse the response body\n        response_body = open_ai_models.ChatResponse.parse_raw(response.text)\n\n        # Create the response\n        response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n\n        # Add the response to the chat\n        self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=response.message, name='Botto'))\n    else:\n        # Parse the error response body\n        response_body = open_ai_models.ErrorResponse.parse_raw(response.text)\n\n        # Create the response\n        response = SimpleOpenaiResponse(False, response_body.error.message)\n\n    # Return the response\n    return response\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.get_image_url","title":"<code>get_image_url(prompt)</code>","text":"<p>Get an image response from OpenAI</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use</p> required <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The image response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def get_image_url(self, prompt: str) -&gt; SimpleOpenaiResponse:\n\"\"\"Get an image response from OpenAI\n\n    Args:\n        prompt (str): The prompt to use\n\n    Returns:\n        SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n    \"\"\"\n\n    # Create the request body\n    request_body = open_ai_models.ImageRequest(prompt=prompt)\n\n    # Send the request\n    response = requests.post(constants.FULL_IMAGE_URL, json=request_body.dict(), headers=self._headers)\n\n    # Check the status code\n    if response.status_code == requests.codes.OK:\n        # Parse the response body\n        response_body = open_ai_models.ImageResponse.parse_raw(response.text)\n\n        # Create the response\n        response = SimpleOpenaiResponse(True, response_body.data[0].url)\n    else:\n        # Parse the error response body\n        response_body = open_ai_models.ErrorResponse.parse_raw(response.text)\n\n        # Create the response\n        response = SimpleOpenaiResponse(False, response_body.error.message)\n\n    # Return the response\n    return response\n</code></pre>"}]}
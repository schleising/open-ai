{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Simple Openai","text":"<p>This is a simple wrapper for the OpenAI API, which allows you to easily use the API in your projects.</p> <p>It provides both synchronous and asynchronous versions of the wrapper.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install using pip:</p> <pre><code>pip install simple-openai\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#calling-the-api","title":"Calling the API","text":"<p>For the synchronous version, you can use the following code:</p> <p>Synchronous Version</p> <pre><code>from simple_openai import SimpleOpenai\n\ndef main():\n    # Initialise a storage location\n    storage_location = Path(\"/path/to/storage\")\n\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = SimpleOpenai(api_key, system_message, storage_location)\n\n    # Create tasks for the chat response and the image response\n    result = client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\n    result = client.get_image_url(\"A cat\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    main()\n</code></pre> <p>For the asynchronous version, you can use the following code:</p> <p>Asynchronous Version</p> <pre><code>from simple_openai import AsyncSimpleOpenai\nimport asyncio\n\nasync def main():\n    # Initialise a storage location\n    storage_location = Path(\"/path/to/storage\")\n\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = AsyncSimpleOpenai(api_key, system_message, storage_location)\n\n    # Create tasks for the chat response and the image response\n    tasks = [\n        client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\"),\n        client.get_image_url(\"A cat\"),\n    ]\n\n    # Wait for the tasks to complete\n    for task in asyncio.as_completed(tasks):\n        # Get the result\n        result = await task\n\n        # Print the result\n        if result.success:\n            # Print the message\n            print(f'Success: {result.message}')\n        else:\n            # Print the error\n            print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    asyncio.run(main())\n</code></pre>"},{"location":"#output","title":"Output","text":"<p>The output of the functions is a SimpleOpenaiResponse object, which contains the following properties:</p> <ul> <li><code>success</code> - A boolean indicating whether the request was successful or not.</li> <li><code>message</code> - The message returned by the API.</li> </ul>"},{"location":"#functions","title":"Functions","text":"<p>Functions can be added to the client using the <code>add_function</code> method. This method takes a function name and a function as arguments. The function should take an OpenAIFunction object as its first argument, and the Python function itself as the second argument.</p> <p>The Python function should return a string, which will be passed to the API using the <code>function</code> role</p>"},{"location":"#documentation","title":"Documentation","text":"<p>The documentation for the package can be found in the reference section.</p>"},{"location":"simple_openai/async_simple_openai/","title":"AsyncSimpleOpenai","text":"<p>Async Simple OpenAI API wrapper</p> <p>The is the async version of the Simple OpenAI API wrapper which uses the <code>aiohttp</code> library.</p> <p>It is intended for use with asyncio applications.  If you are not using asyncio, you should use the Simple OpenAI API wrapper instead.</p>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai","title":"<code>AsyncSimpleOpenai</code>","text":"<p>Async Simple OpenAI API wrapper</p> <p>This class implements the Async Simple OpenAI API wrapper.</p> <p>To use this class, you need to have an OpenAI API key. You can get one from Openai.</p> <p>An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Your OpenAI API key</p> required <code>system_message</code> <code>str</code> <p>The system message to add to the start of the chat</p> required <code>storage_path</code> <code>Path</code> <p>The path to the storage directory. Defaults to None.</p> <code>None</code> <code>timezone</code> <code>str</code> <p>The timezone to use for the chat messages. Defaults to 'UTC'.</p> <code>'UTC'</code> <p>Example</p> <pre><code>from simple_openai import AsyncSimpleOpenai\nimport asyncio\n\nasync def main():\n    # Get the storage path\n    storage_path = Path(\"/path/to/storage\")\n\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = AsyncSimpleOpenai(api_key, system_message, storage_path)\n\n    # Create tasks for the chat response and the image response\n    tasks = [\n        client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\"),\n        client.get_image_url(\"A cat\"),\n    ]\n\n    # Wait for the tasks to complete\n    for task in asyncio.as_completed(tasks):\n        # Get the result\n        result = await task\n\n        # Print the result\n        if result.success:\n            # Print the message\n            print(f'Success: {result.message}')\n        else:\n            # Print the error\n            print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    asyncio.run(main())\n</code></pre> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>class AsyncSimpleOpenai:\n\"\"\"Async Simple OpenAI API wrapper\n\n    This class implements the Async Simple OpenAI API wrapper.\n\n    To use this class, you need to have an OpenAI API key. You can get one from [Openai](https://platform.openai.com).\n\n    An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.\n\n    Args:\n        api_key (str): Your OpenAI API key\n        system_message (str): The system message to add to the start of the chat\n        storage_path (Path, optional): The path to the storage directory. Defaults to None.\n        timezone (str, optional): The timezone to use for the chat messages. Defaults to 'UTC'.\n\n    !!!Example\n        ```python\n        from simple_openai import AsyncSimpleOpenai\n        import asyncio\n\n        async def main():\n            # Get the storage path\n            storage_path = Path(\"/path/to/storage\")\n\n            # Create a system message\n            system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n            # Create the client\n            client = AsyncSimpleOpenai(api_key, system_message, storage_path)\n\n            # Create tasks for the chat response and the image response\n            tasks = [\n                client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\"),\n                client.get_image_url(\"A cat\"),\n            ]\n\n            # Wait for the tasks to complete\n            for task in asyncio.as_completed(tasks):\n                # Get the result\n                result = await task\n\n                # Print the result\n                if result.success:\n                    # Print the message\n                    print(f'Success: {result.message}')\n                else:\n                    # Print the error\n                    print(f'Error: {result.message}')\n\n        if __name__ == \"__main__\":\n            # Run the main function\n            asyncio.run(main())\n        ```\n    \"\"\"\n    def __init__(self, api_key: str, system_message: str, storage_path: Path | None = None, timezone: str = 'UTC') -&gt; None:\n        self._headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {api_key}'\n        }\n\n        # Create the chat manager\n        self._chat = chat_manager.ChatManager(system_message, storage_path=storage_path, timezone=timezone)\n\n        # Create the function manager\n        self._function_manager = function_manager.FunctionManager()\n\n    def update_system_message(self, system_message: str) -&gt; None:\n\"\"\"Update the system message\n\n        Args:\n            system_message (str): The new system message\n        \"\"\"\n        self._chat.update_system_message(system_message)\n\n    def add_function(self, function_definition: open_ai_models.OpenAIFunction, function: Callable) -&gt; None:\n\"\"\"Add a function to the function manager\n\n        Args:\n            function_definition (open_ai_models.OpenAIFunction): The function definition\n            function (Callable): The function to call\n        \"\"\"\n        self._function_manager.add_function(function_definition, function)\n\n    async def get_chat_response(self, prompt: str, name: str, chat_id: str = constants.DEFAULT_CHAT_ID, add_date_time: bool = False) -&gt; SimpleOpenaiResponse:\n\"\"\"Get a chat response from OpenAI\n\n        An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n        Args:\n            prompt (str): The prompt to use for the chat response\n            name (str): The name of the user\n            chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n            add_date_time (bool, optional): Whether to add the date and time to the message. Defaults to False.\n\n        Returns:\n            SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n\n        \"\"\"\n        # Add the message to the chat\n        messages = self._chat.add_message(open_ai_models.ChatMessage(role='user', content=prompt, name=name), chat_id=chat_id, add_date_time=add_date_time).messages        \n\n        # Create the request body\n        request_body = open_ai_models.ChatRequest(messages=messages, functions=self._function_manager.get_json_function_list(), function_call='auto')\n\n        # Delete the functions from the request body if there are no functions\n        if request_body.functions is None:\n            del request_body.functions\n\n        # Open a session\n        async with aiohttp.ClientSession(headers=self._headers, base_url=constants.BASE_URL) as session:\n            # Send the request\n            async with session.post(constants.CHAT_URL, json=request_body.model_dump()) as response1:\n                # Check the status code\n                if response1.status == 200:\n                    # Get the response content\n                    response_text = await response1.text()\n\n                    # Parse the response body\n                    response_body = open_ai_models.ChatResponse.model_validate_json(response_text)\n\n                    # Check if a function was called\n                    if response_body.choices[0].finish_reason == constants.OPEN_AI_FUNCTION_CALL and response_body.choices[0].message.function_call is not None:\n                        # Call the function\n                        new_prompt = await self._function_manager.async_call_function(response_body.choices[0].message.function_call.name)\n\n                        # Add the response to the chat\n                        self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=response_body.choices[0].message.function_call.model_dump_json(), name='Botto'))\n\n                        # Add the message to the chat\n                        messages = self._chat.add_message(open_ai_models.ChatMessage(role='function', content=new_prompt, name='Botto'), chat_id=chat_id, add_date_time=add_date_time).messages\n\n                        # Create the request body\n                        request_body = open_ai_models.ChatRequest(messages=messages, functions=self._function_manager.get_json_function_list(), function_call='none')\n\n                        # Send the request\n                        async with session.post(constants.CHAT_URL, json=request_body.model_dump()) as response2:\n                            # Check the status code\n                            if response2.status == 200:\n                                # Get the response content\n                                response_text = await response2.text()\n\n                                # Parse the response body\n                                response_body = open_ai_models.ChatResponse.model_validate_json(response_text)\n\n                                # Create the response\n                                if response_body.choices[0].message.content is not None:\n                                    open_ai_response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n                                else:\n                                    open_ai_response = SimpleOpenaiResponse(True, 'No response')\n\n                                # Add the response to the chat\n                                self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=open_ai_response.message, name='Botto'))\n                            else:\n                                # Parse the error response body\n                                response_body = open_ai_models.ErrorResponse.model_validate_json(await response2.text())\n\n                                # Create the response\n                                open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n                    else:\n                        # Create the response\n                        if response_body.choices[0].message.content is not None:\n                            open_ai_response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n                        else:\n                            open_ai_response = SimpleOpenaiResponse(True, 'No response')\n\n                        # Add the response to the chat\n                        self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=open_ai_response.message, name='Botto'))\n                else:\n                    # Parse the error response body\n                    response_body = open_ai_models.ErrorResponse.model_validate_json(await response1.text())\n\n                    # Create the response\n                    open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n\n                # Return the response\n                return open_ai_response\n\n    async def get_image_url(self, prompt: str) -&gt; SimpleOpenaiResponse:\n\"\"\"Get an image response from OpenAI\n\n        Args:\n            prompt (str): The prompt to use\n\n        Returns:\n            SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n        \"\"\"\n\n        # Create the request body\n        request_body = open_ai_models.ImageRequest(prompt=prompt)\n\n        # Open a session\n        async with aiohttp.ClientSession(headers=self._headers, base_url=constants.BASE_URL) as session:\n            # Send the request\n            async with session.post(constants.IMAGE_URL, json=request_body.model_dump()) as response:\n                # Check the status code\n                if response.status == 200:\n                    # Parse the response body\n                    response_body = open_ai_models.ImageResponse.model_validate_json(await response.text())\n\n                    # Create the response\n                    response = SimpleOpenaiResponse(True, response_body.data[0].url)\n                else:\n                    # Parse the error response body\n                    response_body = open_ai_models.ErrorResponse.model_validate_json(await response.text())\n\n                    # Create the response\n                    response = SimpleOpenaiResponse(False, response_body.error.message)\n\n                # Return the response\n                return response\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.add_function","title":"<code>add_function(function_definition, function)</code>","text":"<p>Add a function to the function manager</p> <p>Parameters:</p> Name Type Description Default <code>function_definition</code> <code>OpenAIFunction</code> <p>The function definition</p> required <code>function</code> <code>Callable</code> <p>The function to call</p> required Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>def add_function(self, function_definition: open_ai_models.OpenAIFunction, function: Callable) -&gt; None:\n\"\"\"Add a function to the function manager\n\n    Args:\n        function_definition (open_ai_models.OpenAIFunction): The function definition\n        function (Callable): The function to call\n    \"\"\"\n    self._function_manager.add_function(function_definition, function)\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.get_chat_response","title":"<code>get_chat_response(prompt, name, chat_id=constants.DEFAULT_CHAT_ID, add_date_time=False)</code>  <code>async</code>","text":"<p>Get a chat response from OpenAI</p> <p>An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use for the chat response</p> required <code>name</code> <code>str</code> <p>The name of the user</p> required <code>chat_id</code> <code>str</code> <p>The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.</p> <code>DEFAULT_CHAT_ID</code> <code>add_date_time</code> <code>bool</code> <p>Whether to add the date and time to the message. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The chat response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>async def get_chat_response(self, prompt: str, name: str, chat_id: str = constants.DEFAULT_CHAT_ID, add_date_time: bool = False) -&gt; SimpleOpenaiResponse:\n\"\"\"Get a chat response from OpenAI\n\n    An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n    Args:\n        prompt (str): The prompt to use for the chat response\n        name (str): The name of the user\n        chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n        add_date_time (bool, optional): Whether to add the date and time to the message. Defaults to False.\n\n    Returns:\n        SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n\n    \"\"\"\n    # Add the message to the chat\n    messages = self._chat.add_message(open_ai_models.ChatMessage(role='user', content=prompt, name=name), chat_id=chat_id, add_date_time=add_date_time).messages        \n\n    # Create the request body\n    request_body = open_ai_models.ChatRequest(messages=messages, functions=self._function_manager.get_json_function_list(), function_call='auto')\n\n    # Delete the functions from the request body if there are no functions\n    if request_body.functions is None:\n        del request_body.functions\n\n    # Open a session\n    async with aiohttp.ClientSession(headers=self._headers, base_url=constants.BASE_URL) as session:\n        # Send the request\n        async with session.post(constants.CHAT_URL, json=request_body.model_dump()) as response1:\n            # Check the status code\n            if response1.status == 200:\n                # Get the response content\n                response_text = await response1.text()\n\n                # Parse the response body\n                response_body = open_ai_models.ChatResponse.model_validate_json(response_text)\n\n                # Check if a function was called\n                if response_body.choices[0].finish_reason == constants.OPEN_AI_FUNCTION_CALL and response_body.choices[0].message.function_call is not None:\n                    # Call the function\n                    new_prompt = await self._function_manager.async_call_function(response_body.choices[0].message.function_call.name)\n\n                    # Add the response to the chat\n                    self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=response_body.choices[0].message.function_call.model_dump_json(), name='Botto'))\n\n                    # Add the message to the chat\n                    messages = self._chat.add_message(open_ai_models.ChatMessage(role='function', content=new_prompt, name='Botto'), chat_id=chat_id, add_date_time=add_date_time).messages\n\n                    # Create the request body\n                    request_body = open_ai_models.ChatRequest(messages=messages, functions=self._function_manager.get_json_function_list(), function_call='none')\n\n                    # Send the request\n                    async with session.post(constants.CHAT_URL, json=request_body.model_dump()) as response2:\n                        # Check the status code\n                        if response2.status == 200:\n                            # Get the response content\n                            response_text = await response2.text()\n\n                            # Parse the response body\n                            response_body = open_ai_models.ChatResponse.model_validate_json(response_text)\n\n                            # Create the response\n                            if response_body.choices[0].message.content is not None:\n                                open_ai_response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n                            else:\n                                open_ai_response = SimpleOpenaiResponse(True, 'No response')\n\n                            # Add the response to the chat\n                            self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=open_ai_response.message, name='Botto'))\n                        else:\n                            # Parse the error response body\n                            response_body = open_ai_models.ErrorResponse.model_validate_json(await response2.text())\n\n                            # Create the response\n                            open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n                else:\n                    # Create the response\n                    if response_body.choices[0].message.content is not None:\n                        open_ai_response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n                    else:\n                        open_ai_response = SimpleOpenaiResponse(True, 'No response')\n\n                    # Add the response to the chat\n                    self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=open_ai_response.message, name='Botto'))\n            else:\n                # Parse the error response body\n                response_body = open_ai_models.ErrorResponse.model_validate_json(await response1.text())\n\n                # Create the response\n                open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n\n            # Return the response\n            return open_ai_response\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.get_image_url","title":"<code>get_image_url(prompt)</code>  <code>async</code>","text":"<p>Get an image response from OpenAI</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use</p> required <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The image response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>async def get_image_url(self, prompt: str) -&gt; SimpleOpenaiResponse:\n\"\"\"Get an image response from OpenAI\n\n    Args:\n        prompt (str): The prompt to use\n\n    Returns:\n        SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n    \"\"\"\n\n    # Create the request body\n    request_body = open_ai_models.ImageRequest(prompt=prompt)\n\n    # Open a session\n    async with aiohttp.ClientSession(headers=self._headers, base_url=constants.BASE_URL) as session:\n        # Send the request\n        async with session.post(constants.IMAGE_URL, json=request_body.model_dump()) as response:\n            # Check the status code\n            if response.status == 200:\n                # Parse the response body\n                response_body = open_ai_models.ImageResponse.model_validate_json(await response.text())\n\n                # Create the response\n                response = SimpleOpenaiResponse(True, response_body.data[0].url)\n            else:\n                # Parse the error response body\n                response_body = open_ai_models.ErrorResponse.model_validate_json(await response.text())\n\n                # Create the response\n                response = SimpleOpenaiResponse(False, response_body.error.message)\n\n            # Return the response\n            return response\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.update_system_message","title":"<code>update_system_message(system_message)</code>","text":"<p>Update the system message</p> <p>Parameters:</p> Name Type Description Default <code>system_message</code> <code>str</code> <p>The new system message</p> required Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>def update_system_message(self, system_message: str) -&gt; None:\n\"\"\"Update the system message\n\n    Args:\n        system_message (str): The new system message\n    \"\"\"\n    self._chat.update_system_message(system_message)\n</code></pre>"},{"location":"simple_openai/chat_manager/","title":"ChatManager","text":"<p>Chat manager for the simple openai app</p> <p>This module contains the chat manager for the simple openai app.</p> <p>The chat manager is used to manage the chat messages and create the chat, it limits the number of messages in the chat to 21 by default and adds the system message to the start of the list.</p>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager","title":"<code>ChatManager</code>","text":"<p>The chat manager</p> <p>This class is used to manage the chat messages and create the chat, it limits the number of messages in the chat to 21 by default and adds the system message to the start of the list.</p> <p>It can optionally handle messages from multiple chats separately and store them in a file.</p> <p>On initialisation, the chat manager will try to load the chat history from the file.  If the file does not exist, it will create a new chat history.</p> <p>Parameters:</p> Name Type Description Default <code>system_message</code> <code>str</code> <p>The system message to add to the start of the chat</p> required <code>max_messages</code> <code>int</code> <p>The maximum number of messages in the chat. Defaults to 21.</p> <code>MAX_CHAT_HISTORY</code> <code>storage_path</code> <code>Path</code> <p>The path to the storage directory. Defaults to None.</p> <code>None</code> <code>timezone</code> <code>str</code> <p>The timezone to use for the chat messages. Defaults to 'UTC'.</p> <code>'UTC'</code> Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>class ChatManager:\n\"\"\"The chat manager\n\n    This class is used to manage the chat messages and create the chat, it limits the number of messages in the chat to 21 by default and adds the system message to the start of the list.\n\n    It can optionally handle messages from multiple chats separately and store them in a file.\n\n    On initialisation, the chat manager will try to load the chat history from the file.  If the file does not exist, it will create a new chat history.\n\n    Args:\n        system_message (str): The system message to add to the start of the chat\n        max_messages (int, optional): The maximum number of messages in the chat. Defaults to 21.\n        storage_path (Path, optional): The path to the storage directory. Defaults to None.\n        timezone (str, optional): The timezone to use for the chat messages. Defaults to 'UTC'.\n    \"\"\"\n    def __init__(self, system_message: str, max_messages: int = MAX_CHAT_HISTORY, storage_path: Path | None = None, timezone: str = 'UTC') -&gt; None:\n        self._system_message = system_message\n        self._max_messages = max_messages\n        self._storage_path = storage_path\n        self._timezone = ZoneInfo(timezone)\n\n        # If a storage path is provided, create the storage directory\n        if self._storage_path is not None:\n            self._storage_path.mkdir(parents=True, exist_ok=True)\n\n            # Try to load the chat history\n            try:\n                # Load the chat history\n                with open(self._storage_path / CHAT_HISTORY_FILE, 'rb') as f:\n                    # Load the chat history\n                    self._messages: dict[str, deque[open_ai_models.ChatMessage]] = pickle.load(f)\n            except FileNotFoundError:\n                # initialise a deque of messages not including the system message\n                self._messages: dict[str, deque[open_ai_models.ChatMessage]] = {}\n        else:\n            # initialise a deque of messages not including the system message\n            self._messages: dict[str, deque[open_ai_models.ChatMessage]] = {}\n\n    def update_system_message(self, system_message: str) -&gt; None:\n\"\"\"Update the system message\n\n        Args:\n            system_message (str): The new system message\n        \"\"\"\n        self._system_message = system_message\n\n    def add_message(self, message: open_ai_models.ChatMessage, chat_id: str = DEFAULT_CHAT_ID, add_date_time: bool = False) -&gt; open_ai_models.Chat:\n\"\"\"Add a message to the chat\n\n        Args:\n            message (open_ai_models.ChatMessage): The message to add to the chat\n            chat_id (str, optional): The ID of the chat to add the message to. Defaults to DEFAULT_CHAT_ID.\n            add_date_time (bool, optional): Whether to add the date and time to the start of the prompt. Defaults to False.\n\n        Returns:\n            open_ai_models.Chat: The chat\n        \"\"\"\n        # If the chat ID is not in the messages, create a new deque\n        if chat_id not in self._messages:\n            self._messages[chat_id] = deque(maxlen=self._max_messages)\n\n        # Add the message to the deque\n        self._messages[chat_id].append(message)\n\n        # If a storage path is provided, save the chat history\n        if self._storage_path is not None:\n            # Save the chat history\n            with open(self._storage_path / CHAT_HISTORY_FILE, 'wb') as f:\n                pickle.dump(self._messages, f)\n\n        # Update the system message with the date and time in iso format if required\n        if add_date_time:\n            system_message = f'The date and time is {datetime.now(tz=self._timezone).isoformat()} give answers in timezone {self._timezone.key}.\\n{self._system_message}'\n        else:\n            system_message = self._system_message\n\n        # Create the chat adding the system message to the start\n        chat = open_ai_models.Chat(messages=[\n            open_ai_models.ChatMessage(role='system', content=system_message, name='System')\n        ] + list(self._messages[chat_id]))\n\n        # Return the chat\n        return chat\n</code></pre>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager.add_message","title":"<code>add_message(message, chat_id=DEFAULT_CHAT_ID, add_date_time=False)</code>","text":"<p>Add a message to the chat</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>ChatMessage</code> <p>The message to add to the chat</p> required <code>chat_id</code> <code>str</code> <p>The ID of the chat to add the message to. Defaults to DEFAULT_CHAT_ID.</p> <code>DEFAULT_CHAT_ID</code> <code>add_date_time</code> <code>bool</code> <p>Whether to add the date and time to the start of the prompt. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Chat</code> <p>open_ai_models.Chat: The chat</p> Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>def add_message(self, message: open_ai_models.ChatMessage, chat_id: str = DEFAULT_CHAT_ID, add_date_time: bool = False) -&gt; open_ai_models.Chat:\n\"\"\"Add a message to the chat\n\n    Args:\n        message (open_ai_models.ChatMessage): The message to add to the chat\n        chat_id (str, optional): The ID of the chat to add the message to. Defaults to DEFAULT_CHAT_ID.\n        add_date_time (bool, optional): Whether to add the date and time to the start of the prompt. Defaults to False.\n\n    Returns:\n        open_ai_models.Chat: The chat\n    \"\"\"\n    # If the chat ID is not in the messages, create a new deque\n    if chat_id not in self._messages:\n        self._messages[chat_id] = deque(maxlen=self._max_messages)\n\n    # Add the message to the deque\n    self._messages[chat_id].append(message)\n\n    # If a storage path is provided, save the chat history\n    if self._storage_path is not None:\n        # Save the chat history\n        with open(self._storage_path / CHAT_HISTORY_FILE, 'wb') as f:\n            pickle.dump(self._messages, f)\n\n    # Update the system message with the date and time in iso format if required\n    if add_date_time:\n        system_message = f'The date and time is {datetime.now(tz=self._timezone).isoformat()} give answers in timezone {self._timezone.key}.\\n{self._system_message}'\n    else:\n        system_message = self._system_message\n\n    # Create the chat adding the system message to the start\n    chat = open_ai_models.Chat(messages=[\n        open_ai_models.ChatMessage(role='system', content=system_message, name='System')\n    ] + list(self._messages[chat_id]))\n\n    # Return the chat\n    return chat\n</code></pre>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager.update_system_message","title":"<code>update_system_message(system_message)</code>","text":"<p>Update the system message</p> <p>Parameters:</p> Name Type Description Default <code>system_message</code> <code>str</code> <p>The new system message</p> required Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>def update_system_message(self, system_message: str) -&gt; None:\n\"\"\"Update the system message\n\n    Args:\n        system_message (str): The new system message\n    \"\"\"\n    self._system_message = system_message\n</code></pre>"},{"location":"simple_openai/function_manager/","title":"FunctionManager","text":"<p>This module contains the function manager.</p> <p>The function manager is used to manage the functions that can be called by the bot.</p> <p>Define a function using the OpenAIFunction model from models.py and add it to the function manager using the add_function method.</p> <p>The function should return a string.</p> <p>The function can optionally take keyword arguments, the keyword arguments should be defined in the OpenAIFunction model.</p> <p>Call the function using the call_function method for synchronous functions or the async_call_function method for asynchronous functions.</p>"},{"location":"simple_openai/function_manager/#src.simple_openai.function_manager.FunctionManager","title":"<code>FunctionManager</code>","text":"<p>Function manager</p> <p>This class manages the functions that can be called by the bot.</p> Source code in <code>src/simple_openai/function_manager.py</code> <pre><code>class FunctionManager:\n\"\"\"Function manager\n\n    This class manages the functions that can be called by the bot.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._functions: dict[str, OpenAIFunctionMapping] = {}\n\n    def add_function(self, function_definition: open_ai_models.OpenAIFunction, function: Callable) -&gt; None:\n\"\"\"Add a function to the function manager\n\n        Args:\n            function_definition (OpenAIFunction): The function definition\n            function (Callable): The function to call\n        \"\"\"\n        # Add the function to the function manager\n        self._functions[function_definition.name] = OpenAIFunctionMapping(function_definition, function)\n\n    def get_json_function_list(self) -&gt; list[open_ai_models.OpenAIFunction] | None:\n\"\"\"Get the list of functions\n\n        Returns:\n            list[open_ai_models.OpenAIFunction] | None: The list of functions or None if there are no functions\n        \"\"\"\n        # Get the list of functions\n        functions = [function.function_definition for function in self._functions.values()]\n\n        if functions:\n            # Return the list of functions\n            return functions\n        else:\n            # Return None\n            return None\n\n    def call_function(self, function_name: str, **kwargs: dict[str, Any]) -&gt; str:\n\"\"\"Call a function\n\n        Args:\n            function_name (str): The name of the function to call\n            **kwargs: The keyword arguments to pass to the function\n\n        Returns:\n            str: The result of the function\n        \"\"\"\n        # Check that the function exists\n        if function_name not in self._functions:\n            # Return text to tell the bot it hallucinated the function\n            return f'Function {function_name} does not exist, please answer the last question again.'\n        else:\n            # Call the function\n            return self._functions[function_name].function(**kwargs)\n\n    async def async_call_function(self, function_name: str, **kwargs: dict[str, Any]) -&gt; str:\n\"\"\"Call a function\n\n        Args:\n            function_name (str): The name of the function to call\n            **kwargs: The keyword arguments to pass to the function\n\n        Returns:\n            str: The result of the function\n        \"\"\"\n        # Check that the function exists\n        if function_name not in self._functions:\n            # Return text to tell the bot it hallucinated the function\n            return f'Function {function_name} does not exist, please answer the last question again.'\n        else:\n            # Call the function\n            return await self._functions[function_name].function(**kwargs)\n</code></pre>"},{"location":"simple_openai/function_manager/#src.simple_openai.function_manager.FunctionManager.add_function","title":"<code>add_function(function_definition, function)</code>","text":"<p>Add a function to the function manager</p> <p>Parameters:</p> Name Type Description Default <code>function_definition</code> <code>OpenAIFunction</code> <p>The function definition</p> required <code>function</code> <code>Callable</code> <p>The function to call</p> required Source code in <code>src/simple_openai/function_manager.py</code> <pre><code>def add_function(self, function_definition: open_ai_models.OpenAIFunction, function: Callable) -&gt; None:\n\"\"\"Add a function to the function manager\n\n    Args:\n        function_definition (OpenAIFunction): The function definition\n        function (Callable): The function to call\n    \"\"\"\n    # Add the function to the function manager\n    self._functions[function_definition.name] = OpenAIFunctionMapping(function_definition, function)\n</code></pre>"},{"location":"simple_openai/function_manager/#src.simple_openai.function_manager.FunctionManager.async_call_function","title":"<code>async_call_function(function_name, **kwargs)</code>  <code>async</code>","text":"<p>Call a function</p> <p>Parameters:</p> Name Type Description Default <code>function_name</code> <code>str</code> <p>The name of the function to call</p> required <code>**kwargs</code> <code>dict[str, Any]</code> <p>The keyword arguments to pass to the function</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The result of the function</p> Source code in <code>src/simple_openai/function_manager.py</code> <pre><code>async def async_call_function(self, function_name: str, **kwargs: dict[str, Any]) -&gt; str:\n\"\"\"Call a function\n\n    Args:\n        function_name (str): The name of the function to call\n        **kwargs: The keyword arguments to pass to the function\n\n    Returns:\n        str: The result of the function\n    \"\"\"\n    # Check that the function exists\n    if function_name not in self._functions:\n        # Return text to tell the bot it hallucinated the function\n        return f'Function {function_name} does not exist, please answer the last question again.'\n    else:\n        # Call the function\n        return await self._functions[function_name].function(**kwargs)\n</code></pre>"},{"location":"simple_openai/function_manager/#src.simple_openai.function_manager.FunctionManager.call_function","title":"<code>call_function(function_name, **kwargs)</code>","text":"<p>Call a function</p> <p>Parameters:</p> Name Type Description Default <code>function_name</code> <code>str</code> <p>The name of the function to call</p> required <code>**kwargs</code> <code>dict[str, Any]</code> <p>The keyword arguments to pass to the function</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The result of the function</p> Source code in <code>src/simple_openai/function_manager.py</code> <pre><code>def call_function(self, function_name: str, **kwargs: dict[str, Any]) -&gt; str:\n\"\"\"Call a function\n\n    Args:\n        function_name (str): The name of the function to call\n        **kwargs: The keyword arguments to pass to the function\n\n    Returns:\n        str: The result of the function\n    \"\"\"\n    # Check that the function exists\n    if function_name not in self._functions:\n        # Return text to tell the bot it hallucinated the function\n        return f'Function {function_name} does not exist, please answer the last question again.'\n    else:\n        # Call the function\n        return self._functions[function_name].function(**kwargs)\n</code></pre>"},{"location":"simple_openai/function_manager/#src.simple_openai.function_manager.FunctionManager.get_json_function_list","title":"<code>get_json_function_list()</code>","text":"<p>Get the list of functions</p> <p>Returns:</p> Type Description <code>list[open_ai_models.OpenAIFunction] | None</code> <p>list[open_ai_models.OpenAIFunction] | None: The list of functions or None if there are no functions</p> Source code in <code>src/simple_openai/function_manager.py</code> <pre><code>def get_json_function_list(self) -&gt; list[open_ai_models.OpenAIFunction] | None:\n\"\"\"Get the list of functions\n\n    Returns:\n        list[open_ai_models.OpenAIFunction] | None: The list of functions or None if there are no functions\n    \"\"\"\n    # Get the list of functions\n    functions = [function.function_definition for function in self._functions.values()]\n\n    if functions:\n        # Return the list of functions\n        return functions\n    else:\n        # Return None\n        return None\n</code></pre>"},{"location":"simple_openai/function_manager/#src.simple_openai.function_manager.OpenAIFunctionMapping","title":"<code>OpenAIFunctionMapping</code>  <code>dataclass</code>","text":"<p>OpenAI function mapping</p> <p>This class represents an OpenAI function mapping.</p> <p>Parameters:</p> Name Type Description Default <code>function_definition</code> <code>OpenAIFunction</code> <p>The description of the function</p> required <code>function</code> <code>Callable</code> <p>The function to call</p> required Source code in <code>src/simple_openai/function_manager.py</code> <pre><code>@dataclass\nclass OpenAIFunctionMapping:\n\"\"\"OpenAI function mapping\n\n    This class represents an OpenAI function mapping.\n\n    Args:\n        function_definition (OpenAIFunction): The description of the function\n        function (Callable): The function to call\n    \"\"\"\n    function_definition: open_ai_models.OpenAIFunction\n    function: Callable\n</code></pre>"},{"location":"simple_openai/public_models/","title":"Public Models","text":"<p>OpenAI API models</p> <p>This module contains the models for the OpenAI API.</p> <p>The models are used to validate the data sent to and received from the OpenAI API.</p> <p>The models are based on the OpenAI API documentation and use Pydantic to help serialise and deserialise the JSON.</p>"},{"location":"simple_openai/public_models/#src.simple_openai.models.open_ai_models.OpenAIFunction","title":"<code>OpenAIFunction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>OpenAI function</p> <p>This class represents an OpenAI function.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the function</p> <code>description</code> <code>str</code> <p>The description of the function, used by OpenAI to decide whether to use the function</p> <code>parameters</code> <code>OpenAIParameters</code> <p>The parameters of the function</p> Source code in <code>src/simple_openai/models/open_ai_models.py</code> <pre><code>class OpenAIFunction(BaseModel):\n\"\"\" OpenAI function\n\n    This class represents an OpenAI function.\n\n    Attributes:\n        name (str): The name of the function\n        description (str): The description of the function, used by OpenAI to decide whether to use the function\n        parameters (OpenAIParameters): The parameters of the function\n    \"\"\"\n    name: str\n    description: str\n    parameters: OpenAIParameters\n</code></pre>"},{"location":"simple_openai/public_models/#src.simple_openai.models.open_ai_models.OpenAIParameter","title":"<code>OpenAIParameter</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>OpenAI parameter</p> <p>This class represents an OpenAI parameter.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the parameter</p> <code>description</code> <code>str</code> <p>The description of the parameter, used by OpenAI to decide whether to use the parameter</p> Source code in <code>src/simple_openai/models/open_ai_models.py</code> <pre><code>class OpenAIParameter(BaseModel):\n\"\"\" OpenAI parameter\n\n    This class represents an OpenAI parameter.\n\n    Attributes:\n        type (str): The type of the parameter\n        description (str): The description of the parameter, used by OpenAI to decide whether to use the parameter\n    \"\"\"\n    type: str\n    description: str\n</code></pre>"},{"location":"simple_openai/public_models/#src.simple_openai.models.open_ai_models.OpenAIParameters","title":"<code>OpenAIParameters</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>OpenAI parameters</p> <p>This class represents a list of OpenAI parameters.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the parameters</p> <code>properties</code> <code>dict[str, OpenAIParameter]</code> <p>The parameters</p> <code>required</code> <code>list[str]</code> <p>The required parameters. Defaults to [].</p> Source code in <code>src/simple_openai/models/open_ai_models.py</code> <pre><code>class OpenAIParameters(BaseModel):\n\"\"\" OpenAI parameters\n\n    This class represents a list of OpenAI parameters.\n\n    Attributes:\n        type (str): The type of the parameters\n        properties (dict[str, OpenAIParameter]): The parameters\n        required (list[str], optional): The required parameters. Defaults to [].\n    \"\"\"\n    type: str = 'object'\n    properties: dict[str, OpenAIParameter]\n    required: list[str] = []\n</code></pre>"},{"location":"simple_openai/responses/","title":"SimpleOpenaiResponse","text":""},{"location":"simple_openai/responses/#src.simple_openai.responses.SimpleOpenaiResponse","title":"<code>SimpleOpenaiResponse</code>  <code>dataclass</code>","text":"<p>Simple OpenAI API response</p> <p>This class represents a response from the Simple OpenAI API.</p> <p>The value of <code>success</code> should be checked before using the value of <code>message</code>.</p> <p>If <code>success</code> is True,</p> <ul> <li>For a chat response, <code>message</code> will contain the chat response.</li> <li>For an image response, <code>message</code> will contain the image URL.</li> </ul> <p>If <code>success</code> is False, <code>message</code> will contain the error message.</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>bool</code> <p>True if the request was successful, False otherwise</p> <code>message</code> <code>str</code> <p>The message of the response</p> Source code in <code>src/simple_openai/responses.py</code> <pre><code>@dataclass\nclass SimpleOpenaiResponse:\n\"\"\"Simple OpenAI API response\n\n    This class represents a response from the Simple OpenAI API.\n\n    The value of `success` should be checked before using the value of `message`.\n\n    If `success` is True,\n\n    - For a chat response, `message` will contain the chat response.\n    - For an image response, `message` will contain the image URL.\n\n    If `success` is False, `message` will contain the error message.\n\n    Attributes:\n        success (bool): True if the request was successful, False otherwise\n        message (str): The message of the response\n    \"\"\"\n    success: bool\n    message: str\n</code></pre>"},{"location":"simple_openai/simple_openai/","title":"SimpleOpenai","text":"<p>Simple OpenAI API wrapper</p> <p>The is the synchronous version of the Simple OpenAI API wrapper which uses the <code>requests</code> library.</p> <p>If you wish to use the async version, you should use the AsyncSimple OpenAI API wrapper instead.</p>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai","title":"<code>SimpleOpenai</code>","text":"<p>Simple OpenAI API wrapper</p> <p>This class implements the Simple OpenAI API wrapper.</p> <p>To use this class, you need to have an OpenAI API key. You can get one from Openai.</p> <p>An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Your OpenAI API key</p> required <code>system_message</code> <code>str</code> <p>The system message to add to the start of the chat</p> required <code>storage_path</code> <code>Path</code> <p>The path to the storage directory. Defaults to None.</p> <code>None</code> <code>timezone</code> <code>str</code> <p>The timezone to use for the chat messages. Defaults to 'UTC'.</p> <code>'UTC'</code> <p>Example</p> <pre><code>from simple_openai import SimpleOpenai\n\ndef main():\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = SimpleOpenai(api_key, system_message)\n\n    # Create tasks for the chat response and the image response\n    result = client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\n    result = client.get_image_url(\"A cat\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    main()\n</code></pre> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>class SimpleOpenai:\n\"\"\"Simple OpenAI API wrapper\n\n    This class implements the Simple OpenAI API wrapper.\n\n    To use this class, you need to have an OpenAI API key. You can get one from [Openai](https://platform.openai.com).\n\n    An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.\n\n    Args:\n        api_key (str): Your OpenAI API key\n        system_message (str): The system message to add to the start of the chat\n        storage_path (Path, optional): The path to the storage directory. Defaults to None.\n        timezone (str, optional): The timezone to use for the chat messages. Defaults to 'UTC'.\n\n    !!!Example\n        ```python\n        from simple_openai import SimpleOpenai\n\n        def main():\n            # Create a system message\n            system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n            # Create the client\n            client = SimpleOpenai(api_key, system_message)\n\n            # Create tasks for the chat response and the image response\n            result = client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\")\n\n            # Print the result\n            if result.success:\n                # Print the message\n                print(f'Success: {result.message}')\n            else:\n                # Print the error\n                print(f'Error: {result.message}')\n\n            result = client.get_image_url(\"A cat\")\n\n            # Print the result\n            if result.success:\n                # Print the message\n                print(f'Success: {result.message}')\n            else:\n                # Print the error\n                print(f'Error: {result.message}')\n\n        if __name__ == \"__main__\":\n            # Run the main function\n            main()\n        ```\n    \"\"\"\n    def __init__(self, api_key: str, system_message: str, storage_path: Path | None = None, timezone: str = 'UTC') -&gt; None:\n        self._headers = {\n            'Content-Type': 'application/json',\n            'Authorization': f'Bearer {api_key}'\n        }\n\n        # Create the chat manager\n        self._chat = chat_manager.ChatManager(system_message, storage_path=storage_path, timezone=timezone)\n\n        # Create the function manager\n        self._function_manager = function_manager.FunctionManager()\n\n    def update_system_message(self, system_message: str) -&gt; None:\n\"\"\"Update the system message\n\n        Args:\n            system_message (str): The new system message\n        \"\"\"\n        self._chat.update_system_message(system_message)\n\n    def add_function(self, function_definition: open_ai_models.OpenAIFunction, function: Callable) -&gt; None:\n\"\"\"Add a function to the function manager\n\n        Args:\n            function_definition (open_ai_models.OpenAIFunction): The function definition\n            function (Callable): The function to call\n        \"\"\"\n        self._function_manager.add_function(function_definition, function)\n\n    def get_chat_response(self, prompt: str, name: str, chat_id: str = constants.DEFAULT_CHAT_ID, add_date_time: bool = False) -&gt; SimpleOpenaiResponse:\n\"\"\"Get a chat response from OpenAI\n\n        An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n        Args:\n            prompt (str): The prompt to use for the chat response\n            name (str): The name of the person talking to the bot\n            chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n            add_date_time (bool, optional): Whether to add the date and time to the start of the prompt. Defaults to False.\n\n        Returns:\n            SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n        \"\"\"\n\n        # Create the request body\n        messages = self._chat.add_message(open_ai_models.ChatMessage(role='user', content=prompt, name=name), chat_id=chat_id, add_date_time=add_date_time).messages        \n\n        # Create the request body\n        request_body = open_ai_models.ChatRequest(messages=messages, functions=self._function_manager.get_json_function_list(), function_call='auto')\n\n        # Delete the functions from the request body if there are no functions\n        if request_body.functions is None:\n            del request_body.functions\n\n        # Send the request\n        response1 = requests.post(constants.FULL_CHAT_URL, json=request_body.model_dump(), headers=self._headers)\n\n        # Check the status code\n        if response1.status_code == requests.codes.OK:\n            # Parse the response body\n            response_body = open_ai_models.ChatResponse.model_validate_json(response1.text)\n\n            # Check if a function was called\n            if response_body.choices[0].finish_reason == constants.OPEN_AI_FUNCTION_CALL and response_body.choices[0].message.function_call is not None:\n                # Call the function\n                new_prompt = self._function_manager.call_function(response_body.choices[0].message.function_call.name)\n\n                # Add the response to the chat\n                self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=response_body.choices[0].message.function_call.model_dump_json(), name='Botto'))\n\n                # Add the message to the chat\n                messages = self._chat.add_message(open_ai_models.ChatMessage(role='function', content=new_prompt, name='Botto'), chat_id=chat_id, add_date_time=add_date_time).messages\n\n                # Create the request body\n                request_body = open_ai_models.ChatRequest(messages=messages, functions=self._function_manager.get_json_function_list(), function_call='none')\n\n                # Send the request\n                response2 = requests.post(constants.FULL_CHAT_URL, json=request_body.model_dump(), headers=self._headers)\n\n                # Check the status code\n                if response2.status_code == requests.codes.OK:\n                    # Parse the response body\n                    response_body = open_ai_models.ChatResponse.model_validate_json(response2.text)\n\n                    # Create the response\n                    if response_body.choices[0].message.content is not None:\n                        open_ai_response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n                    else:\n                        open_ai_response = SimpleOpenaiResponse(True, 'No response')\n\n                    # Add the response to the chat\n                    self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=open_ai_response.message, name='Botto'))\n                else:\n                    # Parse the error response body\n                    response_body = open_ai_models.ErrorResponse.model_validate_json(response2.text)\n\n                    # Create the response\n                    open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n            else:\n                # Create the response\n                if response_body.choices[0].message.content is not None:\n                    open_ai_response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n                else:\n                    open_ai_response = SimpleOpenaiResponse(True, 'No response')\n\n                # Add the response to the chat\n                self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=open_ai_response.message, name='Botto'))\n        else:\n            # Parse the error response body\n            response_body = open_ai_models.ErrorResponse.model_validate_json(response1.text)\n\n            # Create the response\n            open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n\n        # Return the response\n        return open_ai_response\n\n    def get_image_url(self, prompt: str) -&gt; SimpleOpenaiResponse:\n\"\"\"Get an image response from OpenAI\n\n        Args:\n            prompt (str): The prompt to use\n\n        Returns:\n            SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n        \"\"\"\n\n        # Create the request body\n        request_body = open_ai_models.ImageRequest(prompt=prompt)\n\n        # Send the request\n        response = requests.post(constants.FULL_IMAGE_URL, json=request_body.model_dump(), headers=self._headers)\n\n        # Check the status code\n        if response.status_code == requests.codes.OK:\n            # Parse the response body\n            response_body = open_ai_models.ImageResponse.model_validate_json(response.text)\n\n            # Create the response\n            response = SimpleOpenaiResponse(True, response_body.data[0].url)\n        else:\n            # Parse the error response body\n            response_body = open_ai_models.ErrorResponse.model_validate_json(response.text)\n\n            # Create the response\n            response = SimpleOpenaiResponse(False, response_body.error.message)\n\n        # Return the response\n        return response\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.add_function","title":"<code>add_function(function_definition, function)</code>","text":"<p>Add a function to the function manager</p> <p>Parameters:</p> Name Type Description Default <code>function_definition</code> <code>OpenAIFunction</code> <p>The function definition</p> required <code>function</code> <code>Callable</code> <p>The function to call</p> required Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def add_function(self, function_definition: open_ai_models.OpenAIFunction, function: Callable) -&gt; None:\n\"\"\"Add a function to the function manager\n\n    Args:\n        function_definition (open_ai_models.OpenAIFunction): The function definition\n        function (Callable): The function to call\n    \"\"\"\n    self._function_manager.add_function(function_definition, function)\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.get_chat_response","title":"<code>get_chat_response(prompt, name, chat_id=constants.DEFAULT_CHAT_ID, add_date_time=False)</code>","text":"<p>Get a chat response from OpenAI</p> <p>An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use for the chat response</p> required <code>name</code> <code>str</code> <p>The name of the person talking to the bot</p> required <code>chat_id</code> <code>str</code> <p>The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.</p> <code>DEFAULT_CHAT_ID</code> <code>add_date_time</code> <code>bool</code> <p>Whether to add the date and time to the start of the prompt. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The chat response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def get_chat_response(self, prompt: str, name: str, chat_id: str = constants.DEFAULT_CHAT_ID, add_date_time: bool = False) -&gt; SimpleOpenaiResponse:\n\"\"\"Get a chat response from OpenAI\n\n    An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n    Args:\n        prompt (str): The prompt to use for the chat response\n        name (str): The name of the person talking to the bot\n        chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n        add_date_time (bool, optional): Whether to add the date and time to the start of the prompt. Defaults to False.\n\n    Returns:\n        SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n    \"\"\"\n\n    # Create the request body\n    messages = self._chat.add_message(open_ai_models.ChatMessage(role='user', content=prompt, name=name), chat_id=chat_id, add_date_time=add_date_time).messages        \n\n    # Create the request body\n    request_body = open_ai_models.ChatRequest(messages=messages, functions=self._function_manager.get_json_function_list(), function_call='auto')\n\n    # Delete the functions from the request body if there are no functions\n    if request_body.functions is None:\n        del request_body.functions\n\n    # Send the request\n    response1 = requests.post(constants.FULL_CHAT_URL, json=request_body.model_dump(), headers=self._headers)\n\n    # Check the status code\n    if response1.status_code == requests.codes.OK:\n        # Parse the response body\n        response_body = open_ai_models.ChatResponse.model_validate_json(response1.text)\n\n        # Check if a function was called\n        if response_body.choices[0].finish_reason == constants.OPEN_AI_FUNCTION_CALL and response_body.choices[0].message.function_call is not None:\n            # Call the function\n            new_prompt = self._function_manager.call_function(response_body.choices[0].message.function_call.name)\n\n            # Add the response to the chat\n            self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=response_body.choices[0].message.function_call.model_dump_json(), name='Botto'))\n\n            # Add the message to the chat\n            messages = self._chat.add_message(open_ai_models.ChatMessage(role='function', content=new_prompt, name='Botto'), chat_id=chat_id, add_date_time=add_date_time).messages\n\n            # Create the request body\n            request_body = open_ai_models.ChatRequest(messages=messages, functions=self._function_manager.get_json_function_list(), function_call='none')\n\n            # Send the request\n            response2 = requests.post(constants.FULL_CHAT_URL, json=request_body.model_dump(), headers=self._headers)\n\n            # Check the status code\n            if response2.status_code == requests.codes.OK:\n                # Parse the response body\n                response_body = open_ai_models.ChatResponse.model_validate_json(response2.text)\n\n                # Create the response\n                if response_body.choices[0].message.content is not None:\n                    open_ai_response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n                else:\n                    open_ai_response = SimpleOpenaiResponse(True, 'No response')\n\n                # Add the response to the chat\n                self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=open_ai_response.message, name='Botto'))\n            else:\n                # Parse the error response body\n                response_body = open_ai_models.ErrorResponse.model_validate_json(response2.text)\n\n                # Create the response\n                open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n        else:\n            # Create the response\n            if response_body.choices[0].message.content is not None:\n                open_ai_response = SimpleOpenaiResponse(True, response_body.choices[0].message.content)\n            else:\n                open_ai_response = SimpleOpenaiResponse(True, 'No response')\n\n            # Add the response to the chat\n            self._chat.add_message(open_ai_models.ChatMessage(role='assistant', content=open_ai_response.message, name='Botto'))\n    else:\n        # Parse the error response body\n        response_body = open_ai_models.ErrorResponse.model_validate_json(response1.text)\n\n        # Create the response\n        open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n\n    # Return the response\n    return open_ai_response\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.get_image_url","title":"<code>get_image_url(prompt)</code>","text":"<p>Get an image response from OpenAI</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use</p> required <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The image response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def get_image_url(self, prompt: str) -&gt; SimpleOpenaiResponse:\n\"\"\"Get an image response from OpenAI\n\n    Args:\n        prompt (str): The prompt to use\n\n    Returns:\n        SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n    \"\"\"\n\n    # Create the request body\n    request_body = open_ai_models.ImageRequest(prompt=prompt)\n\n    # Send the request\n    response = requests.post(constants.FULL_IMAGE_URL, json=request_body.model_dump(), headers=self._headers)\n\n    # Check the status code\n    if response.status_code == requests.codes.OK:\n        # Parse the response body\n        response_body = open_ai_models.ImageResponse.model_validate_json(response.text)\n\n        # Create the response\n        response = SimpleOpenaiResponse(True, response_body.data[0].url)\n    else:\n        # Parse the error response body\n        response_body = open_ai_models.ErrorResponse.model_validate_json(response.text)\n\n        # Create the response\n        response = SimpleOpenaiResponse(False, response_body.error.message)\n\n    # Return the response\n    return response\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.update_system_message","title":"<code>update_system_message(system_message)</code>","text":"<p>Update the system message</p> <p>Parameters:</p> Name Type Description Default <code>system_message</code> <code>str</code> <p>The new system message</p> required Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def update_system_message(self, system_message: str) -&gt; None:\n\"\"\"Update the system message\n\n    Args:\n        system_message (str): The new system message\n    \"\"\"\n    self._chat.update_system_message(system_message)\n</code></pre>"}]}
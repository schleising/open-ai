{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Simple Openai","text":"<p>This is a simple wrapper for the OpenAI API, which allows you to easily use the API in your projects.</p> <p>It provides both synchronous and asynchronous versions of the wrapper.</p>"},{"location":"#installation","title":"Installation","text":"<p>Install using pip:</p> <pre><code>pip install simple-openai\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#calling-the-api","title":"Calling the API","text":"<p>For the synchronous version, you can use the following code:</p> <p>Synchronous Version</p> <pre><code>from simple_openai import SimpleOpenai\n\ndef main():\n    # Initialise a storage location\n    storage_location = Path(\"/path/to/storage\")\n\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = SimpleOpenai(api_key, system_message, storage_location)\n\n    # Create tasks for the chat response and the image response\n    result = client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\n    result = client.get_image_url(\"A cat\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    main()\n</code></pre> <p>For the asynchronous version, you can use the following code:</p> <p>Asynchronous Version</p> <pre><code>from simple_openai import AsyncSimpleOpenai\nimport asyncio\n\nasync def main():\n    # Initialise a storage location\n    storage_location = Path(\"/path/to/storage\")\n\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = AsyncSimpleOpenai(api_key, system_message, storage_location)\n\n    # Create tasks for the chat response and the image response\n    tasks = [\n        client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\"),\n        client.get_image_url(\"A cat\"),\n    ]\n\n    # Wait for the tasks to complete\n    for task in asyncio.as_completed(tasks):\n        # Get the result\n        result = await task\n\n        # Print the result\n        if result.success:\n            # Print the message\n            print(f'Success: {result.message}')\n        else:\n            # Print the error\n            print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    asyncio.run(main())\n</code></pre>"},{"location":"#output","title":"Output","text":"<p>The output of the functions is a SimpleOpenaiResponse object, which contains the following properties:</p> <ul> <li><code>success</code> - A boolean indicating whether the request was successful or not.</li> <li><code>message</code> - The message returned by the API.</li> </ul>"},{"location":"#functions","title":"Functions","text":"<p>Functions can be added to the client using the <code>add_function</code> method. This method takes a function name and a function as arguments. The function should take an OpenAIFunction object as its first argument, and the Python function itself as the second argument.</p> <p>The Python function should return a string, which will be passed to the API using the <code>function</code> role</p>"},{"location":"#documentation","title":"Documentation","text":"<p>The documentation for the package can be found in the reference section.</p>"},{"location":"simple_openai/async_simple_openai/","title":"AsyncSimpleOpenai","text":"<p>Async Simple OpenAI API wrapper</p> <p>The is the async version of the Simple OpenAI API wrapper which uses the <code>aiohttp</code> library.</p> <p>It is intended for use with asyncio applications.  If you are not using asyncio, you should use the Simple OpenAI API wrapper instead.</p>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai","title":"<code>AsyncSimpleOpenai</code>","text":"<p>Async Simple OpenAI API wrapper</p> <p>This class implements the Async Simple OpenAI API wrapper.</p> <p>To use this class, you need to have an OpenAI API key. You can get one from Openai.</p> <p>An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Your OpenAI API key</p> required <code>system_message</code> <code>str</code> <p>The system message to add to the start of the chat</p> required <code>storage_path</code> <code>Path</code> <p>The path to the storage directory. Defaults to None.</p> <code>None</code> <code>timezone</code> <code>str</code> <p>The timezone to use for the chat messages. Defaults to 'UTC'.</p> <code>'UTC'</code> <p>Example</p> <pre><code>from simple_openai import AsyncSimpleOpenai\nimport asyncio\n\nasync def main():\n    # Get the storage path\n    storage_path = Path(\"/path/to/storage\")\n\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = AsyncSimpleOpenai(api_key, system_message, storage_path)\n\n    # Create tasks for the chat response and the image response\n    tasks = [\n        client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\"),\n        client.get_image_url(\"A cat\"),\n    ]\n\n    # Wait for the tasks to complete\n    for task in asyncio.as_completed(tasks):\n        # Get the result\n        result = await task\n\n        # Print the result\n        if result.success:\n            # Print the message\n            print(f'Success: {result.message}')\n        else:\n            # Print the error\n            print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    asyncio.run(main())\n</code></pre> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>class AsyncSimpleOpenai:\n    \"\"\"Async Simple OpenAI API wrapper\n\n    This class implements the Async Simple OpenAI API wrapper.\n\n    To use this class, you need to have an OpenAI API key. You can get one from [Openai](https://platform.openai.com).\n\n    An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.\n\n    Args:\n        api_key (str): Your OpenAI API key\n        system_message (str): The system message to add to the start of the chat\n        storage_path (Path, optional): The path to the storage directory. Defaults to None.\n        timezone (str, optional): The timezone to use for the chat messages. Defaults to 'UTC'.\n\n    !!!Example\n        ```python\n        from simple_openai import AsyncSimpleOpenai\n        import asyncio\n\n        async def main():\n            # Get the storage path\n            storage_path = Path(\"/path/to/storage\")\n\n            # Create a system message\n            system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n            # Create the client\n            client = AsyncSimpleOpenai(api_key, system_message, storage_path)\n\n            # Create tasks for the chat response and the image response\n            tasks = [\n                client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\"),\n                client.get_image_url(\"A cat\"),\n            ]\n\n            # Wait for the tasks to complete\n            for task in asyncio.as_completed(tasks):\n                # Get the result\n                result = await task\n\n                # Print the result\n                if result.success:\n                    # Print the message\n                    print(f'Success: {result.message}')\n                else:\n                    # Print the error\n                    print(f'Error: {result.message}')\n\n        if __name__ == \"__main__\":\n            # Run the main function\n            asyncio.run(main())\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        system_message: str,\n        storage_path: Path | None = None,\n        timezone: str = \"UTC\",\n    ) -&gt; None:\n        self._headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {api_key}\",\n        }\n\n        # Create the chat manager\n        self._chat = chat_manager.ChatManager(\n            system_message, storage_path=storage_path, timezone=timezone\n        )\n\n        # Create the tool manager\n        self._tool_manager = tool_manager.ToolManager()\n\n    def update_system_message(self, system_message: str) -&gt; None:\n        \"\"\"Update the system message\n\n        Args:\n            system_message (str): The new system message\n        \"\"\"\n        self._chat.update_system_message(system_message)\n\n    def add_tool(\n        self, tool_definition: open_ai_models.OpenAITool, function: Callable\n    ) -&gt; None:\n        \"\"\"Add a tool to the tool manager\n\n        Args:\n            tool_definition (open_ai_models.OpenAITool): The tool definition\n            function (Callable): The function to call\n        \"\"\"\n        self._tool_manager.add_tool(tool_definition, function)\n\n    async def get_chat_response(\n        self,\n        prompt: str,\n        name: str,\n        chat_id: str = constants.DEFAULT_CHAT_ID,\n        add_date_time: bool = False,\n    ) -&gt; SimpleOpenaiResponse:\n        \"\"\"Get a chat response from OpenAI\n\n        An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n        Args:\n            prompt (str): The prompt to use for the chat response\n            name (str): The name of the user\n            chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n            add_date_time (bool, optional): Whether to add the date and time to the message. Defaults to False.\n\n        Returns:\n            SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n\n        \"\"\"\n        # Add the message to the chat\n        messages = self._chat.add_message(\n            open_ai_models.ChatMessage(role=\"user\", content=prompt, name=name),\n            chat_id=chat_id,\n            add_date_time=add_date_time,\n        ).messages\n\n        # Create the request body\n        request_body = open_ai_models.ChatRequest(\n            messages=messages,\n            tools=self._tool_manager.get_json_tool_list(),\n            tool_choice=\"auto\",\n        )\n\n        # Delete the tools from the request body if there are no tools\n        if request_body.tools is None:\n            del request_body.tools\n            del request_body.tool_choice\n\n        # Open a session\n        async with aiohttp.ClientSession(\n            headers=self._headers, base_url=constants.BASE_URL\n        ) as session:\n            # Send the request\n            async with session.post(\n                constants.CHAT_URL, json=request_body.model_dump()\n            ) as response1:\n                # Check the status code\n                if response1.status == 200:\n                    # Get the response content\n                    response_text = await response1.text()\n\n                    # Parse the response body\n                    response_body = open_ai_models.ChatResponse.model_validate_json(\n                        response_text\n                    )\n\n                    # Check if a function was called\n                    if (\n                        response_body.choices[0].finish_reason\n                        == constants.OPEN_AI_TOOL_CALLS\n                        and response_body.choices[0].message.tool_calls is not None\n                    ):\n                        # Call the function\n                        new_prompt = await self._tool_manager.async_call_function(\n                            response_body.choices[0].message.tool_calls[0].function.name\n                        )\n\n                        # Add the response to the chat\n                        self._chat.add_message(\n                            open_ai_models.ChatMessage(\n                                role=\"assistant\",\n                                content=response_body.choices[0]\n                                .message.tool_calls[0]\n                                .function.model_dump_json(),\n                                name=\"Botto\",\n                            ),\n                            chat_id=chat_id,\n                            add_date_time=add_date_time,\n                        )\n\n                        # Add the message to the chat\n                        messages = self._chat.add_message(\n                            open_ai_models.ChatMessage(\n                                role=\"function\", content=new_prompt, name=\"Botto\"\n                            ),\n                            chat_id=chat_id,\n                            add_date_time=add_date_time,\n                        ).messages\n\n                        # Create the request body\n                        request_body = open_ai_models.ChatRequest(\n                            messages=messages,\n                            tools=self._tool_manager.get_json_tool_list(),\n                            tool_choice=\"none\",\n                        )\n\n                        # Send the request\n                        async with session.post(\n                            constants.CHAT_URL, json=request_body.model_dump()\n                        ) as response2:\n                            # Check the status code\n                            if response2.status == 200:\n                                # Get the response content\n                                response_text = await response2.text()\n\n                                # Parse the response body\n                                response_body = (\n                                    open_ai_models.ChatResponse.model_validate_json(\n                                        response_text\n                                    )\n                                )\n\n                                # Create the response\n                                if response_body.choices[0].message.content is not None:\n                                    open_ai_response = SimpleOpenaiResponse(\n                                        True, response_body.choices[0].message.content\n                                    )\n                                else:\n                                    open_ai_response = SimpleOpenaiResponse(\n                                        True, \"No response\"\n                                    )\n\n                                # Add the response to the chat\n                                self._chat.add_message(\n                                    open_ai_models.ChatMessage(\n                                        role=\"assistant\",\n                                        content=open_ai_response.message,\n                                        name=\"Botto\",\n                                    ),\n                                    chat_id=chat_id,\n                                    add_date_time=add_date_time,\n                                )\n                            else:\n                                # Parse the error response body\n                                response_body = (\n                                    open_ai_models.ErrorResponse.model_validate_json(\n                                        await response2.text()\n                                    )\n                                )\n\n                                # Create the response\n                                open_ai_response = SimpleOpenaiResponse(\n                                    False, response_body.error.message\n                                )\n                    else:\n                        # Create the response\n                        if response_body.choices[0].message.content is not None:\n                            open_ai_response = SimpleOpenaiResponse(\n                                True, response_body.choices[0].message.content\n                            )\n                        else:\n                            open_ai_response = SimpleOpenaiResponse(True, \"No response\")\n\n                        # Add the response to the chat\n                        self._chat.add_message(\n                            open_ai_models.ChatMessage(\n                                role=\"assistant\",\n                                content=open_ai_response.message,\n                                name=\"Botto\",\n                            ),\n                            chat_id=chat_id,\n                            add_date_time=add_date_time,\n                        )\n                else:\n                    # Parse the error response body\n                    response_body = open_ai_models.ErrorResponse.model_validate_json(\n                        await response1.text()\n                    )\n\n                    # Create the response\n                    open_ai_response = SimpleOpenaiResponse(\n                        False, response_body.error.message\n                    )\n\n                # Return the response\n                return open_ai_response\n\n    async def get_image_url(\n        self, prompt: str, style: str = \"vivid\"\n    ) -&gt; SimpleOpenaiResponse:\n        \"\"\"Get an image response from OpenAI\n\n        Args:\n            prompt (str): The prompt to use\n            style (str, optional): The style of the image. Defaults to 'vivid'.\n\n        Returns:\n            SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n        \"\"\"\n\n        # Create the request body\n        request_body = open_ai_models.ImageRequest(prompt=prompt, style=style)\n\n        # Open a session\n        async with aiohttp.ClientSession(\n            headers=self._headers, base_url=constants.BASE_URL\n        ) as session:\n            # Send the request\n            async with session.post(\n                constants.IMAGE_URL, json=request_body.model_dump()\n            ) as response:\n                # Check the status code\n                if response.status == 200:\n                    # Parse the response body\n                    response_body = open_ai_models.ImageResponse.model_validate_json(\n                        await response.text()\n                    )\n\n                    # Create the response\n                    response = SimpleOpenaiResponse(True, response_body.data[0].url)\n                else:\n                    # Parse the error response body\n                    response_body = open_ai_models.ErrorResponse.model_validate_json(\n                        await response.text()\n                    )\n\n                    # Create the response\n                    response = SimpleOpenaiResponse(False, response_body.error.message)\n\n                # Return the response\n                return response\n\n    def get_chat_history(self, chat_id: str) -&gt; str:\n        \"\"\"Get the chat history\n\n        Args:\n            chat_id (str): The ID of the chat\n\n        Returns:\n            str: The chat history\n        \"\"\"\n        # Get the chat history\n        chat_history = self._chat.get_chat(chat_id)\n\n        # Return the chat history\n        return chat_history\n\n    def get_truncated_chat_history(self, chat_id: str) -&gt; str:\n        \"\"\"Get the truncated chat history, limited to the last 4,000 characters\n\n        Args:\n            chat_id (str): The ID of the chat\n\n        Returns:\n            str: The truncated chat history\n        \"\"\"\n        # Get the chat history\n        chat_history = self._chat.get_truncated_chat(chat_id)\n\n        # Return the chat history\n        return chat_history\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.add_tool","title":"<code>add_tool(tool_definition, function)</code>","text":"<p>Add a tool to the tool manager</p> <p>Parameters:</p> Name Type Description Default <code>tool_definition</code> <code>OpenAITool</code> <p>The tool definition</p> required <code>function</code> <code>Callable</code> <p>The function to call</p> required Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>def add_tool(\n    self, tool_definition: open_ai_models.OpenAITool, function: Callable\n) -&gt; None:\n    \"\"\"Add a tool to the tool manager\n\n    Args:\n        tool_definition (open_ai_models.OpenAITool): The tool definition\n        function (Callable): The function to call\n    \"\"\"\n    self._tool_manager.add_tool(tool_definition, function)\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.get_chat_history","title":"<code>get_chat_history(chat_id)</code>","text":"<p>Get the chat history</p> <p>Parameters:</p> Name Type Description Default <code>chat_id</code> <code>str</code> <p>The ID of the chat</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The chat history</p> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>def get_chat_history(self, chat_id: str) -&gt; str:\n    \"\"\"Get the chat history\n\n    Args:\n        chat_id (str): The ID of the chat\n\n    Returns:\n        str: The chat history\n    \"\"\"\n    # Get the chat history\n    chat_history = self._chat.get_chat(chat_id)\n\n    # Return the chat history\n    return chat_history\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.get_chat_response","title":"<code>get_chat_response(prompt, name, chat_id=constants.DEFAULT_CHAT_ID, add_date_time=False)</code>  <code>async</code>","text":"<p>Get a chat response from OpenAI</p> <p>An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use for the chat response</p> required <code>name</code> <code>str</code> <p>The name of the user</p> required <code>chat_id</code> <code>str</code> <p>The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.</p> <code>DEFAULT_CHAT_ID</code> <code>add_date_time</code> <code>bool</code> <p>Whether to add the date and time to the message. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The chat response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>async def get_chat_response(\n    self,\n    prompt: str,\n    name: str,\n    chat_id: str = constants.DEFAULT_CHAT_ID,\n    add_date_time: bool = False,\n) -&gt; SimpleOpenaiResponse:\n    \"\"\"Get a chat response from OpenAI\n\n    An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n    Args:\n        prompt (str): The prompt to use for the chat response\n        name (str): The name of the user\n        chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n        add_date_time (bool, optional): Whether to add the date and time to the message. Defaults to False.\n\n    Returns:\n        SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n\n    \"\"\"\n    # Add the message to the chat\n    messages = self._chat.add_message(\n        open_ai_models.ChatMessage(role=\"user\", content=prompt, name=name),\n        chat_id=chat_id,\n        add_date_time=add_date_time,\n    ).messages\n\n    # Create the request body\n    request_body = open_ai_models.ChatRequest(\n        messages=messages,\n        tools=self._tool_manager.get_json_tool_list(),\n        tool_choice=\"auto\",\n    )\n\n    # Delete the tools from the request body if there are no tools\n    if request_body.tools is None:\n        del request_body.tools\n        del request_body.tool_choice\n\n    # Open a session\n    async with aiohttp.ClientSession(\n        headers=self._headers, base_url=constants.BASE_URL\n    ) as session:\n        # Send the request\n        async with session.post(\n            constants.CHAT_URL, json=request_body.model_dump()\n        ) as response1:\n            # Check the status code\n            if response1.status == 200:\n                # Get the response content\n                response_text = await response1.text()\n\n                # Parse the response body\n                response_body = open_ai_models.ChatResponse.model_validate_json(\n                    response_text\n                )\n\n                # Check if a function was called\n                if (\n                    response_body.choices[0].finish_reason\n                    == constants.OPEN_AI_TOOL_CALLS\n                    and response_body.choices[0].message.tool_calls is not None\n                ):\n                    # Call the function\n                    new_prompt = await self._tool_manager.async_call_function(\n                        response_body.choices[0].message.tool_calls[0].function.name\n                    )\n\n                    # Add the response to the chat\n                    self._chat.add_message(\n                        open_ai_models.ChatMessage(\n                            role=\"assistant\",\n                            content=response_body.choices[0]\n                            .message.tool_calls[0]\n                            .function.model_dump_json(),\n                            name=\"Botto\",\n                        ),\n                        chat_id=chat_id,\n                        add_date_time=add_date_time,\n                    )\n\n                    # Add the message to the chat\n                    messages = self._chat.add_message(\n                        open_ai_models.ChatMessage(\n                            role=\"function\", content=new_prompt, name=\"Botto\"\n                        ),\n                        chat_id=chat_id,\n                        add_date_time=add_date_time,\n                    ).messages\n\n                    # Create the request body\n                    request_body = open_ai_models.ChatRequest(\n                        messages=messages,\n                        tools=self._tool_manager.get_json_tool_list(),\n                        tool_choice=\"none\",\n                    )\n\n                    # Send the request\n                    async with session.post(\n                        constants.CHAT_URL, json=request_body.model_dump()\n                    ) as response2:\n                        # Check the status code\n                        if response2.status == 200:\n                            # Get the response content\n                            response_text = await response2.text()\n\n                            # Parse the response body\n                            response_body = (\n                                open_ai_models.ChatResponse.model_validate_json(\n                                    response_text\n                                )\n                            )\n\n                            # Create the response\n                            if response_body.choices[0].message.content is not None:\n                                open_ai_response = SimpleOpenaiResponse(\n                                    True, response_body.choices[0].message.content\n                                )\n                            else:\n                                open_ai_response = SimpleOpenaiResponse(\n                                    True, \"No response\"\n                                )\n\n                            # Add the response to the chat\n                            self._chat.add_message(\n                                open_ai_models.ChatMessage(\n                                    role=\"assistant\",\n                                    content=open_ai_response.message,\n                                    name=\"Botto\",\n                                ),\n                                chat_id=chat_id,\n                                add_date_time=add_date_time,\n                            )\n                        else:\n                            # Parse the error response body\n                            response_body = (\n                                open_ai_models.ErrorResponse.model_validate_json(\n                                    await response2.text()\n                                )\n                            )\n\n                            # Create the response\n                            open_ai_response = SimpleOpenaiResponse(\n                                False, response_body.error.message\n                            )\n                else:\n                    # Create the response\n                    if response_body.choices[0].message.content is not None:\n                        open_ai_response = SimpleOpenaiResponse(\n                            True, response_body.choices[0].message.content\n                        )\n                    else:\n                        open_ai_response = SimpleOpenaiResponse(True, \"No response\")\n\n                    # Add the response to the chat\n                    self._chat.add_message(\n                        open_ai_models.ChatMessage(\n                            role=\"assistant\",\n                            content=open_ai_response.message,\n                            name=\"Botto\",\n                        ),\n                        chat_id=chat_id,\n                        add_date_time=add_date_time,\n                    )\n            else:\n                # Parse the error response body\n                response_body = open_ai_models.ErrorResponse.model_validate_json(\n                    await response1.text()\n                )\n\n                # Create the response\n                open_ai_response = SimpleOpenaiResponse(\n                    False, response_body.error.message\n                )\n\n            # Return the response\n            return open_ai_response\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.get_image_url","title":"<code>get_image_url(prompt, style='vivid')</code>  <code>async</code>","text":"<p>Get an image response from OpenAI</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use</p> required <code>style</code> <code>str</code> <p>The style of the image. Defaults to 'vivid'.</p> <code>'vivid'</code> <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The image response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>async def get_image_url(\n    self, prompt: str, style: str = \"vivid\"\n) -&gt; SimpleOpenaiResponse:\n    \"\"\"Get an image response from OpenAI\n\n    Args:\n        prompt (str): The prompt to use\n        style (str, optional): The style of the image. Defaults to 'vivid'.\n\n    Returns:\n        SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n    \"\"\"\n\n    # Create the request body\n    request_body = open_ai_models.ImageRequest(prompt=prompt, style=style)\n\n    # Open a session\n    async with aiohttp.ClientSession(\n        headers=self._headers, base_url=constants.BASE_URL\n    ) as session:\n        # Send the request\n        async with session.post(\n            constants.IMAGE_URL, json=request_body.model_dump()\n        ) as response:\n            # Check the status code\n            if response.status == 200:\n                # Parse the response body\n                response_body = open_ai_models.ImageResponse.model_validate_json(\n                    await response.text()\n                )\n\n                # Create the response\n                response = SimpleOpenaiResponse(True, response_body.data[0].url)\n            else:\n                # Parse the error response body\n                response_body = open_ai_models.ErrorResponse.model_validate_json(\n                    await response.text()\n                )\n\n                # Create the response\n                response = SimpleOpenaiResponse(False, response_body.error.message)\n\n            # Return the response\n            return response\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.get_truncated_chat_history","title":"<code>get_truncated_chat_history(chat_id)</code>","text":"<p>Get the truncated chat history, limited to the last 4,000 characters</p> <p>Parameters:</p> Name Type Description Default <code>chat_id</code> <code>str</code> <p>The ID of the chat</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The truncated chat history</p> Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>def get_truncated_chat_history(self, chat_id: str) -&gt; str:\n    \"\"\"Get the truncated chat history, limited to the last 4,000 characters\n\n    Args:\n        chat_id (str): The ID of the chat\n\n    Returns:\n        str: The truncated chat history\n    \"\"\"\n    # Get the chat history\n    chat_history = self._chat.get_truncated_chat(chat_id)\n\n    # Return the chat history\n    return chat_history\n</code></pre>"},{"location":"simple_openai/async_simple_openai/#src.simple_openai.async_simple_openai.AsyncSimpleOpenai.update_system_message","title":"<code>update_system_message(system_message)</code>","text":"<p>Update the system message</p> <p>Parameters:</p> Name Type Description Default <code>system_message</code> <code>str</code> <p>The new system message</p> required Source code in <code>src/simple_openai/async_simple_openai.py</code> <pre><code>def update_system_message(self, system_message: str) -&gt; None:\n    \"\"\"Update the system message\n\n    Args:\n        system_message (str): The new system message\n    \"\"\"\n    self._chat.update_system_message(system_message)\n</code></pre>"},{"location":"simple_openai/chat_manager/","title":"ChatManager","text":"<p>Chat manager for the simple openai app</p> <p>This module contains the chat manager for the simple openai app.</p> <p>The chat manager is used to manage the chat messages and create the chat, it limits the number of messages in the chat to 21 by default and adds the system message to the start of the list.</p>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager","title":"<code>ChatManager</code>","text":"<p>The chat manager</p> <p>This class is used to manage the chat messages and create the chat, it limits the number of messages in the chat to 21 by default and adds the system message to the start of the list.</p> <p>It can optionally handle messages from multiple chats separately and store them in a file.</p> <p>On initialisation, the chat manager will try to load the chat history from the file.  If the file does not exist, it will create a new chat history.</p> <p>Parameters:</p> Name Type Description Default <code>system_message</code> <code>str</code> <p>The system message to add to the start of the chat</p> required <code>max_messages</code> <code>int</code> <p>The maximum number of messages in the chat. Defaults to 21.</p> <code>MAX_CHAT_HISTORY</code> <code>storage_path</code> <code>Path</code> <p>The path to the storage directory. Defaults to None.</p> <code>None</code> <code>timezone</code> <code>str</code> <p>The timezone to use for the chat messages. Defaults to 'UTC'.</p> <code>'UTC'</code> Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>class ChatManager:\n    \"\"\"The chat manager\n\n    This class is used to manage the chat messages and create the chat, it limits the number of messages in the chat to 21 by default and adds the system message to the start of the list.\n\n    It can optionally handle messages from multiple chats separately and store them in a file.\n\n    On initialisation, the chat manager will try to load the chat history from the file.  If the file does not exist, it will create a new chat history.\n\n    Args:\n        system_message (str): The system message to add to the start of the chat\n        max_messages (int, optional): The maximum number of messages in the chat. Defaults to 21.\n        storage_path (Path, optional): The path to the storage directory. Defaults to None.\n        timezone (str, optional): The timezone to use for the chat messages. Defaults to 'UTC'.\n    \"\"\"\n\n    def __init__(\n        self,\n        system_message: str,\n        max_messages: int = MAX_CHAT_HISTORY,\n        storage_path: Path | None = None,\n        timezone: str = \"UTC\",\n    ) -&gt; None:\n        self._system_message = system_message\n        self._max_messages = max_messages\n        self._storage_path = storage_path\n        self._timezone = ZoneInfo(timezone)\n\n        # If a storage path is provided, create the storage directory\n        if self._storage_path is not None:\n            self._storage_path.mkdir(parents=True, exist_ok=True)\n\n            # Try to load the chat history\n            try:\n                # Load the chat history\n                with open(self._storage_path / CHAT_HISTORY_FILE, \"rb\") as f:\n                    # Load the chat history\n                    self._messages: dict[str, deque[open_ai_models.ChatMessage]] = (\n                        pickle.load(f)\n                    )\n            except FileNotFoundError:\n                # initialise a deque of messages not including the system message\n                self._messages: dict[str, deque[open_ai_models.ChatMessage]] = {}\n        else:\n            # initialise a deque of messages not including the system message\n            self._messages: dict[str, deque[open_ai_models.ChatMessage]] = {}\n\n    def update_system_message(self, system_message: str) -&gt; None:\n        \"\"\"Update the system message\n\n        Args:\n            system_message (str): The new system message\n        \"\"\"\n        self._system_message = system_message\n\n    def add_message(\n        self,\n        message: open_ai_models.ChatMessage,\n        chat_id: str = DEFAULT_CHAT_ID,\n        add_date_time: bool = False,\n    ) -&gt; open_ai_models.Chat:\n        \"\"\"Add a message to the chat\n\n        Args:\n            message (open_ai_models.ChatMessage): The message to add to the chat\n            chat_id (str, optional): The ID of the chat to add the message to. Defaults to DEFAULT_CHAT_ID.\n            add_date_time (bool, optional): Whether to add the date and time to the start of the prompt. Defaults to False.\n\n        Returns:\n            open_ai_models.Chat: The chat\n        \"\"\"\n        # If the chat ID is not in the messages, create a new deque\n        if chat_id not in self._messages:\n            self._messages[chat_id] = deque(maxlen=self._max_messages)\n\n        # Add the message to the deque\n        self._messages[chat_id].append(message)\n\n        # If a storage path is provided, save the chat history\n        if self._storage_path is not None:\n            # Save the chat history\n            with open(self._storage_path / CHAT_HISTORY_FILE, \"wb\") as f:\n                pickle.dump(self._messages, f)\n\n        # Update the system message with the date and time in iso format if required\n        if add_date_time:\n            system_message = f\"The date and time is {datetime.now(tz=self._timezone).isoformat()} give answers in timezone {self._timezone.key}.\\n{self._system_message}\"\n        else:\n            system_message = self._system_message\n\n        # Create the chat adding the system message to the start\n        chat = open_ai_models.Chat(\n            messages=[\n                open_ai_models.ChatMessage(\n                    role=\"system\", content=system_message, name=\"System\"\n                )\n            ]\n            + list(self._messages[chat_id])\n        )\n\n        # Return the chat\n        return chat\n\n    def get_chat(self, chat_id: str = DEFAULT_CHAT_ID) -&gt; str:\n        \"\"\"Get the chat\n\n        Args:\n            chat_id (str, optional): The ID of the chat to get. Defaults to DEFAULT_CHAT_ID.\n\n        Returns:\n            str: The chat\n        \"\"\"\n        # If the chat ID is not in the messages, create a new deque\n        if chat_id not in self._messages:\n            return \"\"\n\n        # Get the chat\n        chat = self._messages[chat_id]\n\n        # Parse the most recent 10 chat messages to a string with each name and message on a new line\n        chat_str = \"\\n\".join([f\"{message.name}: {message.content}\" for message in chat])\n\n        # Return the chat\n        return chat_str\n\n    def get_truncated_chat(self, chat_id: str = DEFAULT_CHAT_ID) -&gt; str:\n        \"\"\"Get the truncated chat, limited to the last 4,000 characters\n\n        Args:\n            chat_id (str, optional): The ID of the chat to get. Defaults to DEFAULT_CHAT_ID.\n\n        Returns:\n            str: The truncated chat\n        \"\"\"\n        # If the chat ID is not in the messages, create a new deque\n        if chat_id not in self._messages:\n            return \"\"\n\n        # Get the chat\n        chat = self._messages[chat_id]\n\n        # Parse the most recent 10 chat messages to a string with each name and message on a new line\n        chat_str = \"\\n\".join([f\"{message.name}: {message.content}\" for message in chat])\n\n        # Get the last 4,000 characters of the chat\n        chat_str = chat_str[-4000:]\n\n        # Return the chat\n        return chat_str\n</code></pre>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager.add_message","title":"<code>add_message(message, chat_id=DEFAULT_CHAT_ID, add_date_time=False)</code>","text":"<p>Add a message to the chat</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>ChatMessage</code> <p>The message to add to the chat</p> required <code>chat_id</code> <code>str</code> <p>The ID of the chat to add the message to. Defaults to DEFAULT_CHAT_ID.</p> <code>DEFAULT_CHAT_ID</code> <code>add_date_time</code> <code>bool</code> <p>Whether to add the date and time to the start of the prompt. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Chat</code> <p>open_ai_models.Chat: The chat</p> Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>def add_message(\n    self,\n    message: open_ai_models.ChatMessage,\n    chat_id: str = DEFAULT_CHAT_ID,\n    add_date_time: bool = False,\n) -&gt; open_ai_models.Chat:\n    \"\"\"Add a message to the chat\n\n    Args:\n        message (open_ai_models.ChatMessage): The message to add to the chat\n        chat_id (str, optional): The ID of the chat to add the message to. Defaults to DEFAULT_CHAT_ID.\n        add_date_time (bool, optional): Whether to add the date and time to the start of the prompt. Defaults to False.\n\n    Returns:\n        open_ai_models.Chat: The chat\n    \"\"\"\n    # If the chat ID is not in the messages, create a new deque\n    if chat_id not in self._messages:\n        self._messages[chat_id] = deque(maxlen=self._max_messages)\n\n    # Add the message to the deque\n    self._messages[chat_id].append(message)\n\n    # If a storage path is provided, save the chat history\n    if self._storage_path is not None:\n        # Save the chat history\n        with open(self._storage_path / CHAT_HISTORY_FILE, \"wb\") as f:\n            pickle.dump(self._messages, f)\n\n    # Update the system message with the date and time in iso format if required\n    if add_date_time:\n        system_message = f\"The date and time is {datetime.now(tz=self._timezone).isoformat()} give answers in timezone {self._timezone.key}.\\n{self._system_message}\"\n    else:\n        system_message = self._system_message\n\n    # Create the chat adding the system message to the start\n    chat = open_ai_models.Chat(\n        messages=[\n            open_ai_models.ChatMessage(\n                role=\"system\", content=system_message, name=\"System\"\n            )\n        ]\n        + list(self._messages[chat_id])\n    )\n\n    # Return the chat\n    return chat\n</code></pre>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager.get_chat","title":"<code>get_chat(chat_id=DEFAULT_CHAT_ID)</code>","text":"<p>Get the chat</p> <p>Parameters:</p> Name Type Description Default <code>chat_id</code> <code>str</code> <p>The ID of the chat to get. Defaults to DEFAULT_CHAT_ID.</p> <code>DEFAULT_CHAT_ID</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The chat</p> Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>def get_chat(self, chat_id: str = DEFAULT_CHAT_ID) -&gt; str:\n    \"\"\"Get the chat\n\n    Args:\n        chat_id (str, optional): The ID of the chat to get. Defaults to DEFAULT_CHAT_ID.\n\n    Returns:\n        str: The chat\n    \"\"\"\n    # If the chat ID is not in the messages, create a new deque\n    if chat_id not in self._messages:\n        return \"\"\n\n    # Get the chat\n    chat = self._messages[chat_id]\n\n    # Parse the most recent 10 chat messages to a string with each name and message on a new line\n    chat_str = \"\\n\".join([f\"{message.name}: {message.content}\" for message in chat])\n\n    # Return the chat\n    return chat_str\n</code></pre>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager.get_truncated_chat","title":"<code>get_truncated_chat(chat_id=DEFAULT_CHAT_ID)</code>","text":"<p>Get the truncated chat, limited to the last 4,000 characters</p> <p>Parameters:</p> Name Type Description Default <code>chat_id</code> <code>str</code> <p>The ID of the chat to get. Defaults to DEFAULT_CHAT_ID.</p> <code>DEFAULT_CHAT_ID</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The truncated chat</p> Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>def get_truncated_chat(self, chat_id: str = DEFAULT_CHAT_ID) -&gt; str:\n    \"\"\"Get the truncated chat, limited to the last 4,000 characters\n\n    Args:\n        chat_id (str, optional): The ID of the chat to get. Defaults to DEFAULT_CHAT_ID.\n\n    Returns:\n        str: The truncated chat\n    \"\"\"\n    # If the chat ID is not in the messages, create a new deque\n    if chat_id not in self._messages:\n        return \"\"\n\n    # Get the chat\n    chat = self._messages[chat_id]\n\n    # Parse the most recent 10 chat messages to a string with each name and message on a new line\n    chat_str = \"\\n\".join([f\"{message.name}: {message.content}\" for message in chat])\n\n    # Get the last 4,000 characters of the chat\n    chat_str = chat_str[-4000:]\n\n    # Return the chat\n    return chat_str\n</code></pre>"},{"location":"simple_openai/chat_manager/#src.simple_openai.chat_manager.ChatManager.update_system_message","title":"<code>update_system_message(system_message)</code>","text":"<p>Update the system message</p> <p>Parameters:</p> Name Type Description Default <code>system_message</code> <code>str</code> <p>The new system message</p> required Source code in <code>src/simple_openai/chat_manager.py</code> <pre><code>def update_system_message(self, system_message: str) -&gt; None:\n    \"\"\"Update the system message\n\n    Args:\n        system_message (str): The new system message\n    \"\"\"\n    self._system_message = system_message\n</code></pre>"},{"location":"simple_openai/public_models/","title":"Public Models","text":"<p>OpenAI API models</p> <p>This module contains the models for the OpenAI API.</p> <p>The models are used to validate the data sent to and received from the OpenAI API.</p> <p>The models are based on the OpenAI API documentation and use Pydantic to help serialise and deserialise the JSON.</p>"},{"location":"simple_openai/public_models/#src.simple_openai.models.open_ai_models.OpenAIFunction","title":"<code>OpenAIFunction</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>OpenAI function</p> <p>This class represents an OpenAI function.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the function</p> <code>description</code> <code>str</code> <p>The description of the function, used by OpenAI to decide whether to use the function</p> <code>parameters</code> <code>OpenAIParameters</code> <p>The parameters of the function</p> Source code in <code>src/simple_openai/models/open_ai_models.py</code> <pre><code>class OpenAIFunction(BaseModel):\n    \"\"\"OpenAI function\n\n    This class represents an OpenAI function.\n\n    Attributes:\n        name (str): The name of the function\n        description (str): The description of the function, used by OpenAI to decide whether to use the function\n        parameters (OpenAIParameters): The parameters of the function\n    \"\"\"\n\n    name: str\n    description: str\n    parameters: OpenAIParameters\n</code></pre>"},{"location":"simple_openai/public_models/#src.simple_openai.models.open_ai_models.OpenAIParameter","title":"<code>OpenAIParameter</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>OpenAI parameter</p> <p>This class represents an OpenAI parameter.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the parameter</p> <code>description</code> <code>str</code> <p>The description of the parameter, used by OpenAI to decide whether to use the parameter</p> Source code in <code>src/simple_openai/models/open_ai_models.py</code> <pre><code>class OpenAIParameter(BaseModel):\n    \"\"\"OpenAI parameter\n\n    This class represents an OpenAI parameter.\n\n    Attributes:\n        type (str): The type of the parameter\n        description (str): The description of the parameter, used by OpenAI to decide whether to use the parameter\n    \"\"\"\n\n    type: str\n    description: str\n</code></pre>"},{"location":"simple_openai/public_models/#src.simple_openai.models.open_ai_models.OpenAIParameters","title":"<code>OpenAIParameters</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>OpenAI parameters</p> <p>This class represents a list of OpenAI parameters.</p> <p>Attributes:</p> Name Type Description <code>type</code> <code>str</code> <p>The type of the parameters</p> <code>properties</code> <code>dict[str, OpenAIParameter]</code> <p>The parameters</p> <code>required</code> <code>list[str]</code> <p>The required parameters. Defaults to [].</p> Source code in <code>src/simple_openai/models/open_ai_models.py</code> <pre><code>class OpenAIParameters(BaseModel):\n    \"\"\"OpenAI parameters\n\n    This class represents a list of OpenAI parameters.\n\n    Attributes:\n        type (str): The type of the parameters\n        properties (dict[str, OpenAIParameter]): The parameters\n        required (list[str], optional): The required parameters. Defaults to [].\n    \"\"\"\n\n    type: str = \"object\"\n    properties: dict[str, OpenAIParameter]\n    required: list[str] = []\n</code></pre>"},{"location":"simple_openai/responses/","title":"SimpleOpenaiResponse","text":""},{"location":"simple_openai/responses/#src.simple_openai.responses.SimpleOpenaiResponse","title":"<code>SimpleOpenaiResponse</code>  <code>dataclass</code>","text":"<p>Simple OpenAI API response</p> <p>This class represents a response from the Simple OpenAI API.</p> <p>The value of <code>success</code> should be checked before using the value of <code>message</code>.</p> <p>If <code>success</code> is True,</p> <ul> <li>For a chat response, <code>message</code> will contain the chat response.</li> <li>For an image response, <code>message</code> will contain the image URL.</li> </ul> <p>If <code>success</code> is False, <code>message</code> will contain the error message.</p> <p>Attributes:</p> Name Type Description <code>success</code> <code>bool</code> <p>True if the request was successful, False otherwise</p> <code>message</code> <code>str</code> <p>The message of the response</p> Source code in <code>src/simple_openai/responses.py</code> <pre><code>@dataclass\nclass SimpleOpenaiResponse:\n    \"\"\"Simple OpenAI API response\n\n    This class represents a response from the Simple OpenAI API.\n\n    The value of `success` should be checked before using the value of `message`.\n\n    If `success` is True,\n\n    - For a chat response, `message` will contain the chat response.\n    - For an image response, `message` will contain the image URL.\n\n    If `success` is False, `message` will contain the error message.\n\n    Attributes:\n        success (bool): True if the request was successful, False otherwise\n        message (str): The message of the response\n    \"\"\"\n\n    success: bool\n    message: str\n</code></pre>"},{"location":"simple_openai/simple_openai/","title":"SimpleOpenai","text":"<p>Simple OpenAI API wrapper</p> <p>The is the synchronous version of the Simple OpenAI API wrapper which uses the <code>requests</code> library.</p> <p>If you wish to use the async version, you should use the AsyncSimple OpenAI API wrapper instead.</p>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai","title":"<code>SimpleOpenai</code>","text":"<p>Simple OpenAI API wrapper</p> <p>This class implements the Simple OpenAI API wrapper.</p> <p>To use this class, you need to have an OpenAI API key. You can get one from Openai.</p> <p>An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Your OpenAI API key</p> required <code>system_message</code> <code>str</code> <p>The system message to add to the start of the chat</p> required <code>storage_path</code> <code>Path</code> <p>The path to the storage directory. Defaults to None.</p> <code>None</code> <code>timezone</code> <code>str</code> <p>The timezone to use for the chat messages. Defaults to 'UTC'.</p> <code>'UTC'</code> <p>Example</p> <pre><code>from simple_openai import SimpleOpenai\n\ndef main():\n    # Create a system message\n    system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n    # Create the client\n    client = SimpleOpenai(api_key, system_message)\n\n    # Create tasks for the chat response and the image response\n    result = client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\n    result = client.get_image_url(\"A cat\")\n\n    # Print the result\n    if result.success:\n        # Print the message\n        print(f'Success: {result.message}')\n    else:\n        # Print the error\n        print(f'Error: {result.message}')\n\nif __name__ == \"__main__\":\n    # Run the main function\n    main()\n</code></pre> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>class SimpleOpenai:\n    \"\"\"Simple OpenAI API wrapper\n\n    This class implements the Simple OpenAI API wrapper.\n\n    To use this class, you need to have an OpenAI API key. You can get one from [Openai](https://platform.openai.com).\n\n    An optional storage path can be provided.  If a storage path is provided, the chat messages will be stored in the directory specified by the storage path.  If no storage path is provided, the chat messages will not be stored.\n\n    Args:\n        api_key (str): Your OpenAI API key\n        system_message (str): The system message to add to the start of the chat\n        storage_path (Path, optional): The path to the storage directory. Defaults to None.\n        timezone (str, optional): The timezone to use for the chat messages. Defaults to 'UTC'.\n\n    !!!Example\n        ```python\n        from simple_openai import SimpleOpenai\n\n        def main():\n            # Create a system message\n            system_message = \"You are a helpful chatbot. You are very friendly and helpful. You are a good friend to have.\"\n\n            # Create the client\n            client = SimpleOpenai(api_key, system_message)\n\n            # Create tasks for the chat response and the image response\n            result = client.get_chat_response(\"Hello, how are you?\", name=\"Bob\", chat_id=\"Group 1\")\n\n            # Print the result\n            if result.success:\n                # Print the message\n                print(f'Success: {result.message}')\n            else:\n                # Print the error\n                print(f'Error: {result.message}')\n\n            result = client.get_image_url(\"A cat\")\n\n            # Print the result\n            if result.success:\n                # Print the message\n                print(f'Success: {result.message}')\n            else:\n                # Print the error\n                print(f'Error: {result.message}')\n\n        if __name__ == \"__main__\":\n            # Run the main function\n            main()\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        system_message: str,\n        storage_path: Path | None = None,\n        timezone: str = \"UTC\",\n    ) -&gt; None:\n        self._headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f\"Bearer {api_key}\",\n        }\n\n        # Create the chat manager\n        self._chat = chat_manager.ChatManager(\n            system_message, storage_path=storage_path, timezone=timezone\n        )\n\n        # Create the tool manager\n        self._tool_manager = tool_manager.ToolManager()\n\n    def update_system_message(self, system_message: str) -&gt; None:\n        \"\"\"Update the system message\n\n        Args:\n            system_message (str): The new system message\n        \"\"\"\n        self._chat.update_system_message(system_message)\n\n    def add_tool(\n        self, tool_definition: open_ai_models.OpenAITool, function: Callable\n    ) -&gt; None:\n        \"\"\"Add a tool to the tool manager\n\n        Args:\n            tool_definition (open_ai_models.OpenAITool): The tool definition\n            function (Callable): The function to call\n        \"\"\"\n        self._tool_manager.add_tool(tool_definition, function)\n\n    def get_chat_response(\n        self,\n        prompt: str,\n        name: str,\n        chat_id: str = constants.DEFAULT_CHAT_ID,\n        add_date_time: bool = False,\n    ) -&gt; SimpleOpenaiResponse:\n        \"\"\"Get a chat response from OpenAI\n\n        An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n        Args:\n            prompt (str): The prompt to use for the chat response\n            name (str): The name of the person talking to the bot\n            chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n            add_date_time (bool, optional): Whether to add the date and time to the start of the prompt. Defaults to False.\n\n        Returns:\n            SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n        \"\"\"\n\n        # Create the request body\n        messages = self._chat.add_message(\n            open_ai_models.ChatMessage(role=\"user\", content=prompt, name=name),\n            chat_id=chat_id,\n            add_date_time=add_date_time,\n        ).messages\n\n        # Create the request body\n        request_body = open_ai_models.ChatRequest(\n            messages=messages,\n            tools=self._tool_manager.get_json_tool_list(),\n            tool_choice=\"auto\",\n        )\n\n        # Delete the tools from the request body if there are no tool\n        if request_body.tools is None:\n            del request_body.tools\n            del request_body.tool_choice\n\n        # Send the request\n        response1 = requests.post(\n            constants.FULL_CHAT_URL,\n            json=request_body.model_dump(),\n            headers=self._headers,\n        )\n\n        # Check the status code\n        if response1.status_code == requests.codes.OK:\n            # Parse the response body\n            response_body = open_ai_models.ChatResponse.model_validate_json(\n                response1.text\n            )\n\n            # Check if a function was called\n            if (\n                response_body.choices[0].finish_reason == constants.OPEN_AI_TOOL_CALLS\n                and response_body.choices[0].message.tool_calls is not None\n            ):\n                # Call the function\n                new_prompt = self._tool_manager.call_function(\n                    response_body.choices[0].message.tool_calls[0].function.name\n                )\n\n                # Add the response to the chat\n                self._chat.add_message(\n                    open_ai_models.ChatMessage(\n                        role=\"assistant\",\n                        content=response_body.choices[0]\n                        .message.tool_calls[0]\n                        .function.model_dump_json(),\n                        name=\"Botto\",\n                    ),\n                    chat_id=chat_id,\n                    add_date_time=add_date_time,\n                )\n\n                # Add the message to the chat\n                messages = self._chat.add_message(\n                    open_ai_models.ChatMessage(\n                        role=\"function\", content=new_prompt, name=\"Botto\"\n                    ),\n                    chat_id=chat_id,\n                    add_date_time=add_date_time,\n                ).messages\n\n                # Create the request body\n                request_body = open_ai_models.ChatRequest(\n                    messages=messages,\n                    tools=self._tool_manager.get_json_tool_list(),\n                    tool_choice=\"none\",\n                )\n\n                # Send the request\n                response2 = requests.post(\n                    constants.FULL_CHAT_URL,\n                    json=request_body.model_dump(),\n                    headers=self._headers,\n                )\n\n                # Check the status code\n                if response2.status_code == requests.codes.OK:\n                    # Parse the response body\n                    response_body = open_ai_models.ChatResponse.model_validate_json(\n                        response2.text\n                    )\n\n                    # Create the response\n                    if response_body.choices[0].message.content is not None:\n                        open_ai_response = SimpleOpenaiResponse(\n                            True, response_body.choices[0].message.content\n                        )\n                    else:\n                        open_ai_response = SimpleOpenaiResponse(True, \"No response\")\n\n                    # Add the response to the chat\n                    self._chat.add_message(\n                        open_ai_models.ChatMessage(\n                            role=\"assistant\",\n                            content=open_ai_response.message,\n                            name=\"Botto\",\n                        ),\n                        chat_id=chat_id,\n                        add_date_time=add_date_time,\n                    )\n                else:\n                    # Parse the error response body\n                    response_body = open_ai_models.ErrorResponse.model_validate_json(\n                        response2.text\n                    )\n\n                    # Create the response\n                    open_ai_response = SimpleOpenaiResponse(\n                        False, response_body.error.message\n                    )\n            else:\n                # Create the response\n                if response_body.choices[0].message.content is not None:\n                    open_ai_response = SimpleOpenaiResponse(\n                        True, response_body.choices[0].message.content\n                    )\n                else:\n                    open_ai_response = SimpleOpenaiResponse(True, \"No response\")\n\n                # Add the response to the chat\n                self._chat.add_message(\n                    open_ai_models.ChatMessage(\n                        role=\"assistant\", content=open_ai_response.message, name=\"Botto\"\n                    ),\n                    chat_id=chat_id,\n                    add_date_time=add_date_time,\n                )\n        else:\n            # Parse the error response body\n            response_body = open_ai_models.ErrorResponse.model_validate_json(\n                response1.text\n            )\n\n            # Create the response\n            open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n\n        # Return the response\n        return open_ai_response\n\n    def get_image_url(self, prompt: str, style: str = \"vivid\") -&gt; SimpleOpenaiResponse:\n        \"\"\"Get an image response from OpenAI\n\n        Args:\n            prompt (str): The prompt to use\n            style (str, optional): The style of the image. Defaults to 'vivid'.\n\n        Returns:\n            SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n        \"\"\"\n\n        # Create the request body\n        request_body = open_ai_models.ImageRequest(prompt=prompt, style=style)\n\n        # Send the request\n        response = requests.post(\n            constants.FULL_IMAGE_URL,\n            json=request_body.model_dump(),\n            headers=self._headers,\n        )\n\n        # Check the status code\n        if response.status_code == requests.codes.OK:\n            # Parse the response body\n            response_body = open_ai_models.ImageResponse.model_validate_json(\n                response.text\n            )\n\n            # Create the response\n            response = SimpleOpenaiResponse(True, response_body.data[0].url)\n        else:\n            # Parse the error response body\n            response_body = open_ai_models.ErrorResponse.model_validate_json(\n                response.text\n            )\n\n            # Create the response\n            response = SimpleOpenaiResponse(False, response_body.error.message)\n\n        # Return the response\n        return response\n\n    def get_chat_history(self, chat_id: str) -&gt; str:\n        \"\"\"Get the chat history\n\n        Args:\n            chat_id (str): The ID of the chat\n\n        Returns:\n            str: The chat history\n        \"\"\"\n        # Get the chat history\n        chat_history = self._chat.get_chat(chat_id)\n\n        # Return the chat history\n        return chat_history\n\n    def get_truncated_chat_history(self, chat_id: str) -&gt; str:\n        \"\"\"Get the truncated chat history, limited to the last 4,000 characters\n\n        Args:\n            chat_id (str): The ID of the chat\n\n        Returns:\n            str: The truncated chat history\n        \"\"\"\n        # Get the chat history\n        chat_history = self._chat.get_truncated_chat(chat_id)\n\n        # Return the chat history\n        return chat_history\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.add_tool","title":"<code>add_tool(tool_definition, function)</code>","text":"<p>Add a tool to the tool manager</p> <p>Parameters:</p> Name Type Description Default <code>tool_definition</code> <code>OpenAITool</code> <p>The tool definition</p> required <code>function</code> <code>Callable</code> <p>The function to call</p> required Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def add_tool(\n    self, tool_definition: open_ai_models.OpenAITool, function: Callable\n) -&gt; None:\n    \"\"\"Add a tool to the tool manager\n\n    Args:\n        tool_definition (open_ai_models.OpenAITool): The tool definition\n        function (Callable): The function to call\n    \"\"\"\n    self._tool_manager.add_tool(tool_definition, function)\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.get_chat_history","title":"<code>get_chat_history(chat_id)</code>","text":"<p>Get the chat history</p> <p>Parameters:</p> Name Type Description Default <code>chat_id</code> <code>str</code> <p>The ID of the chat</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The chat history</p> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def get_chat_history(self, chat_id: str) -&gt; str:\n    \"\"\"Get the chat history\n\n    Args:\n        chat_id (str): The ID of the chat\n\n    Returns:\n        str: The chat history\n    \"\"\"\n    # Get the chat history\n    chat_history = self._chat.get_chat(chat_id)\n\n    # Return the chat history\n    return chat_history\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.get_chat_response","title":"<code>get_chat_response(prompt, name, chat_id=constants.DEFAULT_CHAT_ID, add_date_time=False)</code>","text":"<p>Get a chat response from OpenAI</p> <p>An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use for the chat response</p> required <code>name</code> <code>str</code> <p>The name of the person talking to the bot</p> required <code>chat_id</code> <code>str</code> <p>The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.</p> <code>DEFAULT_CHAT_ID</code> <code>add_date_time</code> <code>bool</code> <p>Whether to add the date and time to the start of the prompt. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The chat response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def get_chat_response(\n    self,\n    prompt: str,\n    name: str,\n    chat_id: str = constants.DEFAULT_CHAT_ID,\n    add_date_time: bool = False,\n) -&gt; SimpleOpenaiResponse:\n    \"\"\"Get a chat response from OpenAI\n\n    An optional chat ID can be provided.  If a chat ID is provided, the chat will be continued from the chat with the specified ID.  If no chat ID is provided, all messages will be mixed into a single list.\n\n    Args:\n        prompt (str): The prompt to use for the chat response\n        name (str): The name of the person talking to the bot\n        chat_id (str, optional): The ID of the chat to continue. Defaults to DEFAULT_CHAT_ID.\n        add_date_time (bool, optional): Whether to add the date and time to the start of the prompt. Defaults to False.\n\n    Returns:\n        SimpleOpenaiResponse: The chat response, the value of `success` should be checked before using the value of `message`\n    \"\"\"\n\n    # Create the request body\n    messages = self._chat.add_message(\n        open_ai_models.ChatMessage(role=\"user\", content=prompt, name=name),\n        chat_id=chat_id,\n        add_date_time=add_date_time,\n    ).messages\n\n    # Create the request body\n    request_body = open_ai_models.ChatRequest(\n        messages=messages,\n        tools=self._tool_manager.get_json_tool_list(),\n        tool_choice=\"auto\",\n    )\n\n    # Delete the tools from the request body if there are no tool\n    if request_body.tools is None:\n        del request_body.tools\n        del request_body.tool_choice\n\n    # Send the request\n    response1 = requests.post(\n        constants.FULL_CHAT_URL,\n        json=request_body.model_dump(),\n        headers=self._headers,\n    )\n\n    # Check the status code\n    if response1.status_code == requests.codes.OK:\n        # Parse the response body\n        response_body = open_ai_models.ChatResponse.model_validate_json(\n            response1.text\n        )\n\n        # Check if a function was called\n        if (\n            response_body.choices[0].finish_reason == constants.OPEN_AI_TOOL_CALLS\n            and response_body.choices[0].message.tool_calls is not None\n        ):\n            # Call the function\n            new_prompt = self._tool_manager.call_function(\n                response_body.choices[0].message.tool_calls[0].function.name\n            )\n\n            # Add the response to the chat\n            self._chat.add_message(\n                open_ai_models.ChatMessage(\n                    role=\"assistant\",\n                    content=response_body.choices[0]\n                    .message.tool_calls[0]\n                    .function.model_dump_json(),\n                    name=\"Botto\",\n                ),\n                chat_id=chat_id,\n                add_date_time=add_date_time,\n            )\n\n            # Add the message to the chat\n            messages = self._chat.add_message(\n                open_ai_models.ChatMessage(\n                    role=\"function\", content=new_prompt, name=\"Botto\"\n                ),\n                chat_id=chat_id,\n                add_date_time=add_date_time,\n            ).messages\n\n            # Create the request body\n            request_body = open_ai_models.ChatRequest(\n                messages=messages,\n                tools=self._tool_manager.get_json_tool_list(),\n                tool_choice=\"none\",\n            )\n\n            # Send the request\n            response2 = requests.post(\n                constants.FULL_CHAT_URL,\n                json=request_body.model_dump(),\n                headers=self._headers,\n            )\n\n            # Check the status code\n            if response2.status_code == requests.codes.OK:\n                # Parse the response body\n                response_body = open_ai_models.ChatResponse.model_validate_json(\n                    response2.text\n                )\n\n                # Create the response\n                if response_body.choices[0].message.content is not None:\n                    open_ai_response = SimpleOpenaiResponse(\n                        True, response_body.choices[0].message.content\n                    )\n                else:\n                    open_ai_response = SimpleOpenaiResponse(True, \"No response\")\n\n                # Add the response to the chat\n                self._chat.add_message(\n                    open_ai_models.ChatMessage(\n                        role=\"assistant\",\n                        content=open_ai_response.message,\n                        name=\"Botto\",\n                    ),\n                    chat_id=chat_id,\n                    add_date_time=add_date_time,\n                )\n            else:\n                # Parse the error response body\n                response_body = open_ai_models.ErrorResponse.model_validate_json(\n                    response2.text\n                )\n\n                # Create the response\n                open_ai_response = SimpleOpenaiResponse(\n                    False, response_body.error.message\n                )\n        else:\n            # Create the response\n            if response_body.choices[0].message.content is not None:\n                open_ai_response = SimpleOpenaiResponse(\n                    True, response_body.choices[0].message.content\n                )\n            else:\n                open_ai_response = SimpleOpenaiResponse(True, \"No response\")\n\n            # Add the response to the chat\n            self._chat.add_message(\n                open_ai_models.ChatMessage(\n                    role=\"assistant\", content=open_ai_response.message, name=\"Botto\"\n                ),\n                chat_id=chat_id,\n                add_date_time=add_date_time,\n            )\n    else:\n        # Parse the error response body\n        response_body = open_ai_models.ErrorResponse.model_validate_json(\n            response1.text\n        )\n\n        # Create the response\n        open_ai_response = SimpleOpenaiResponse(False, response_body.error.message)\n\n    # Return the response\n    return open_ai_response\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.get_image_url","title":"<code>get_image_url(prompt, style='vivid')</code>","text":"<p>Get an image response from OpenAI</p> <p>Parameters:</p> Name Type Description Default <code>prompt</code> <code>str</code> <p>The prompt to use</p> required <code>style</code> <code>str</code> <p>The style of the image. Defaults to 'vivid'.</p> <code>'vivid'</code> <p>Returns:</p> Name Type Description <code>SimpleOpenaiResponse</code> <code>SimpleOpenaiResponse</code> <p>The image response, the value of <code>success</code> should be checked before using the value of <code>message</code></p> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def get_image_url(self, prompt: str, style: str = \"vivid\") -&gt; SimpleOpenaiResponse:\n    \"\"\"Get an image response from OpenAI\n\n    Args:\n        prompt (str): The prompt to use\n        style (str, optional): The style of the image. Defaults to 'vivid'.\n\n    Returns:\n        SimpleOpenaiResponse: The image response, the value of `success` should be checked before using the value of `message`\n    \"\"\"\n\n    # Create the request body\n    request_body = open_ai_models.ImageRequest(prompt=prompt, style=style)\n\n    # Send the request\n    response = requests.post(\n        constants.FULL_IMAGE_URL,\n        json=request_body.model_dump(),\n        headers=self._headers,\n    )\n\n    # Check the status code\n    if response.status_code == requests.codes.OK:\n        # Parse the response body\n        response_body = open_ai_models.ImageResponse.model_validate_json(\n            response.text\n        )\n\n        # Create the response\n        response = SimpleOpenaiResponse(True, response_body.data[0].url)\n    else:\n        # Parse the error response body\n        response_body = open_ai_models.ErrorResponse.model_validate_json(\n            response.text\n        )\n\n        # Create the response\n        response = SimpleOpenaiResponse(False, response_body.error.message)\n\n    # Return the response\n    return response\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.get_truncated_chat_history","title":"<code>get_truncated_chat_history(chat_id)</code>","text":"<p>Get the truncated chat history, limited to the last 4,000 characters</p> <p>Parameters:</p> Name Type Description Default <code>chat_id</code> <code>str</code> <p>The ID of the chat</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The truncated chat history</p> Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def get_truncated_chat_history(self, chat_id: str) -&gt; str:\n    \"\"\"Get the truncated chat history, limited to the last 4,000 characters\n\n    Args:\n        chat_id (str): The ID of the chat\n\n    Returns:\n        str: The truncated chat history\n    \"\"\"\n    # Get the chat history\n    chat_history = self._chat.get_truncated_chat(chat_id)\n\n    # Return the chat history\n    return chat_history\n</code></pre>"},{"location":"simple_openai/simple_openai/#src.simple_openai.simple_openai.SimpleOpenai.update_system_message","title":"<code>update_system_message(system_message)</code>","text":"<p>Update the system message</p> <p>Parameters:</p> Name Type Description Default <code>system_message</code> <code>str</code> <p>The new system message</p> required Source code in <code>src/simple_openai/simple_openai.py</code> <pre><code>def update_system_message(self, system_message: str) -&gt; None:\n    \"\"\"Update the system message\n\n    Args:\n        system_message (str): The new system message\n    \"\"\"\n    self._chat.update_system_message(system_message)\n</code></pre>"},{"location":"simple_openai/tool_manager/","title":"ToolManager","text":"<p>This module contains the tool manager.</p> <p>The tool manager is used to manage the toold that can be called by the bot.</p> <p>Define a function using the OpenAITool model from models.py and add it to the tool manager using the add_tool method.</p> <p>The tool should return a string.</p> <p>The tool can optionally take keyword arguments, the keyword arguments should be defined in the OpenAITool model.</p> <p>Call the tool using the call_function method for synchronous functions or the async_call_function method for asynchronous.</p>"},{"location":"simple_openai/tool_manager/#src.simple_openai.tool_manager.OpenAIToolMapping","title":"<code>OpenAIToolMapping</code>  <code>dataclass</code>","text":"<p>OpenAI tool mapping</p> <p>This class represents an OpenAI tool mapping.</p> <p>Parameters:</p> Name Type Description Default <code>tool_definition</code> <code>OpenAITool</code> <p>The description of the tool</p> required <code>function</code> <code>Callable</code> <p>The function to call</p> required Source code in <code>src/simple_openai/tool_manager.py</code> <pre><code>@dataclass\nclass OpenAIToolMapping:\n    \"\"\"OpenAI tool mapping\n\n    This class represents an OpenAI tool mapping.\n\n    Args:\n        tool_definition (OpenAITool): The description of the tool\n        function (Callable): The function to call\n    \"\"\"\n\n    tool_definition: open_ai_models.OpenAITool\n    function: Callable\n</code></pre>"},{"location":"simple_openai/tool_manager/#src.simple_openai.tool_manager.ToolManager","title":"<code>ToolManager</code>","text":"<p>Tool manager</p> <p>This class manages the tools that can be called by the bot.</p> Source code in <code>src/simple_openai/tool_manager.py</code> <pre><code>class ToolManager:\n    \"\"\"Tool manager\n\n    This class manages the tools that can be called by the bot.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        self._tools: dict[str, OpenAIToolMapping] = {}\n\n    def add_tool(\n        self, tool_definition: open_ai_models.OpenAITool, function: Callable\n    ) -&gt; None:\n        \"\"\"Add a tool to the tool manager\n\n        Args:\n            tool_definition (OpenAITool): The tool definition\n            function (Callable): The function to call\n        \"\"\"\n        # Add the function to the function manager\n        self._tools[tool_definition.function.name] = OpenAIToolMapping(\n            tool_definition, function\n        )\n\n    def get_json_tool_list(self) -&gt; list[open_ai_models.OpenAITool] | None:\n        \"\"\"Get the list of tools\n\n        Returns:\n            list[open_ai_models.OpenAITool] | None: The list of tools or None if there are no tools\n        \"\"\"\n        # Get the list of functions\n        tools = [tool.tool_definition for tool in self._tools.values()]\n\n        if tools:\n            # Return the list of functions\n            return tools\n        else:\n            # Return None\n            return None\n\n    def call_function(self, function_name: str, **kwargs: dict[str, Any]) -&gt; str:\n        \"\"\"Call a function\n\n        Args:\n            function_name (str): The name of the function to call\n            **kwargs: The keyword arguments to pass to the function\n\n        Returns:\n            str: The result of the function\n        \"\"\"\n        # Check that the function exists\n        if function_name not in self._tools:\n            # Return text to tell the bot it hallucinated the function\n            return f\"Tool {function_name} does not exist, please answer the last question again.\"\n        else:\n            # Call the function\n            return self._tools[function_name].function(**kwargs)\n\n    async def async_call_function(\n        self, function_name: str, **kwargs: dict[str, Any]\n    ) -&gt; str:\n        \"\"\"Call a function\n\n        Args:\n            function_name (str): The name of the function to call\n            **kwargs: The keyword arguments to pass to the function\n\n        Returns:\n            str: The result of the function\n        \"\"\"\n        # Check that the function exists\n        if function_name not in self._tools:\n            # Return text to tell the bot it hallucinated the function\n            return f\"Function {function_name} does not exist, please answer the last question again.\"\n        else:\n            # Call the function\n            return await self._tools[function_name].function(**kwargs)\n</code></pre>"},{"location":"simple_openai/tool_manager/#src.simple_openai.tool_manager.ToolManager.add_tool","title":"<code>add_tool(tool_definition, function)</code>","text":"<p>Add a tool to the tool manager</p> <p>Parameters:</p> Name Type Description Default <code>tool_definition</code> <code>OpenAITool</code> <p>The tool definition</p> required <code>function</code> <code>Callable</code> <p>The function to call</p> required Source code in <code>src/simple_openai/tool_manager.py</code> <pre><code>def add_tool(\n    self, tool_definition: open_ai_models.OpenAITool, function: Callable\n) -&gt; None:\n    \"\"\"Add a tool to the tool manager\n\n    Args:\n        tool_definition (OpenAITool): The tool definition\n        function (Callable): The function to call\n    \"\"\"\n    # Add the function to the function manager\n    self._tools[tool_definition.function.name] = OpenAIToolMapping(\n        tool_definition, function\n    )\n</code></pre>"},{"location":"simple_openai/tool_manager/#src.simple_openai.tool_manager.ToolManager.async_call_function","title":"<code>async_call_function(function_name, **kwargs)</code>  <code>async</code>","text":"<p>Call a function</p> <p>Parameters:</p> Name Type Description Default <code>function_name</code> <code>str</code> <p>The name of the function to call</p> required <code>**kwargs</code> <code>dict[str, Any]</code> <p>The keyword arguments to pass to the function</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The result of the function</p> Source code in <code>src/simple_openai/tool_manager.py</code> <pre><code>async def async_call_function(\n    self, function_name: str, **kwargs: dict[str, Any]\n) -&gt; str:\n    \"\"\"Call a function\n\n    Args:\n        function_name (str): The name of the function to call\n        **kwargs: The keyword arguments to pass to the function\n\n    Returns:\n        str: The result of the function\n    \"\"\"\n    # Check that the function exists\n    if function_name not in self._tools:\n        # Return text to tell the bot it hallucinated the function\n        return f\"Function {function_name} does not exist, please answer the last question again.\"\n    else:\n        # Call the function\n        return await self._tools[function_name].function(**kwargs)\n</code></pre>"},{"location":"simple_openai/tool_manager/#src.simple_openai.tool_manager.ToolManager.call_function","title":"<code>call_function(function_name, **kwargs)</code>","text":"<p>Call a function</p> <p>Parameters:</p> Name Type Description Default <code>function_name</code> <code>str</code> <p>The name of the function to call</p> required <code>**kwargs</code> <code>dict[str, Any]</code> <p>The keyword arguments to pass to the function</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The result of the function</p> Source code in <code>src/simple_openai/tool_manager.py</code> <pre><code>def call_function(self, function_name: str, **kwargs: dict[str, Any]) -&gt; str:\n    \"\"\"Call a function\n\n    Args:\n        function_name (str): The name of the function to call\n        **kwargs: The keyword arguments to pass to the function\n\n    Returns:\n        str: The result of the function\n    \"\"\"\n    # Check that the function exists\n    if function_name not in self._tools:\n        # Return text to tell the bot it hallucinated the function\n        return f\"Tool {function_name} does not exist, please answer the last question again.\"\n    else:\n        # Call the function\n        return self._tools[function_name].function(**kwargs)\n</code></pre>"},{"location":"simple_openai/tool_manager/#src.simple_openai.tool_manager.ToolManager.get_json_tool_list","title":"<code>get_json_tool_list()</code>","text":"<p>Get the list of tools</p> <p>Returns:</p> Type Description <code>list[OpenAITool] | None</code> <p>list[open_ai_models.OpenAITool] | None: The list of tools or None if there are no tools</p> Source code in <code>src/simple_openai/tool_manager.py</code> <pre><code>def get_json_tool_list(self) -&gt; list[open_ai_models.OpenAITool] | None:\n    \"\"\"Get the list of tools\n\n    Returns:\n        list[open_ai_models.OpenAITool] | None: The list of tools or None if there are no tools\n    \"\"\"\n    # Get the list of functions\n    tools = [tool.tool_definition for tool in self._tools.values()]\n\n    if tools:\n        # Return the list of functions\n        return tools\n    else:\n        # Return None\n        return None\n</code></pre>"}]}